{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b470433c",
   "metadata": {},
   "source": [
    "# FIXME\n",
    "- DRAW ANOTHER SUBSET OT 1000 SAMPLES FOR RAPID PROTOTYPING\n",
    "- SAVE IT AS WELL\n",
    "- THEN DEVELOP ON THIS IN THE NOTEBOOKS\n",
    "- THEN RUN A BACKGROUND JOB ON THE FULL DATASET\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "Here, I will just check if I can get some usable data from the GDELT 2.0 Event\n",
    "Database via Google BigQuery.\n",
    "\n",
    "So far, I didn't decide for which problem to solve and what kind of model to\n",
    "train, because I want to find a suitable dataset first.\n",
    "\n",
    "Here's what I'm looking for data:\n",
    "- with time stamps that's updated regularly, so I can train an initial model\n",
    "and then schedule it to run periodically and monitor it\n",
    "- that's sufficiently large to train a model on\n",
    "- that has some interesting features and a suitable target variable\n",
    "\n",
    "During a brief search, I found the GDELT 2.0 Event Database, which is a public\n",
    "and free database that contains event data from all over the world.\n",
    "It seems to fulfill these requirements and is available via BigQuery.\n",
    "\n",
    "Here, I will check if I can get some data from it and if it's suitable for my\n",
    "needs.\n",
    "\n",
    "## Environment\n",
    "\n",
    "To use this project's uv environment, make sure you installed it according to\n",
    "the instructions in the README.md file.\n",
    "\n",
    "Then, connect to the `.venv` kernel.\n",
    "Check the path to the kernel to make sure it's the right one.\n",
    "It should be `.venv/bin/python`.\n",
    "\n",
    "Run the next cell to check if you use the correct kernel.\n",
    "It should output this:\n",
    "\n",
    "# FIXME: Once I decided for an actual name for the repo, adapt the path!\n",
    "```\n",
    "<path_to_wherever_you_cloned_the_repo_to>/mlopsproject2/.venv/bin/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f6eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fakrueg/projects/courses/datatalks/mlops-zoomcamp/mlopsproject2/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f324b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import mlflow\n",
    "import joblib\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Tuple\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "PATH_REPO = Path(\".\").resolve().parent\n",
    "PATH_DATA = PATH_REPO / \"data\" / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec1866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1755362327633, experiment_id='1', last_update_time=1755362327633, lifecycle_stage='active', name='testing_setup', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set MLFlow tracking URI or rather: basically connect to the MLFlow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# set experiment\n",
    "mlflow.set_experiment(\"testing_setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery Client Setup\n",
    "def setup_bigquery_client():\n",
    "    \"\"\"\n",
    "    Set up BigQuery client using credentials file\n",
    "    \"\"\"\n",
    "    # Check if credentials file exists\n",
    "    cred_path = \"../bigquery-credentials.json\"\n",
    "    if not Path(cred_path).exists():\n",
    "        raise FileNotFoundError(f\"Credentials file not found: {cred_path}\")\n",
    "    \n",
    "    # Set environment variable for this session\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = cred_path\n",
    "    \n",
    "    # Get project ID from environment\n",
    "    project_id = os.getenv('GOOGLE_CLOUD_PROJECT')\n",
    "    if not project_id:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_PROJECT not set in .env file\")\n",
    "    \n",
    "    # Initialize client\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    return client\n",
    "\n",
    "# Initialize BigQuery client\n",
    "try:\n",
    "    client = setup_bigquery_client()\n",
    "    print(f\"BigQuery client initialized successfully!\")\n",
    "    print(f\"Project: {client.project}\")\n",
    "    print(f\"Using credentials from: ./bigquery-credentials.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up BigQuery client: {e}\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ebbb0",
   "metadata": {},
   "source": [
    "# FIXME: Explain why I selected these exact features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_gdelt_query(start_date, end_date, limit=100, dry_run=True):\n",
    "    \"\"\"\n",
    "    Safely query GDELT data with automatic cost estimation\n",
    "    \n",
    "    Args:\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format  \n",
    "        limit (int): Maximum number of rows to return\n",
    "        dry_run (bool): If True, only estimate query cost\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None:\n",
    "        raise ValueError(\"BigQuery client not initialized\")\n",
    "    \n",
    "    # Convert dates to GDELT format (YYYYMMDD) as integers\n",
    "    start_gdelt = int(start_date.replace('-', ''))\n",
    "    end_gdelt = int(end_date.replace('-', ''))\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        SQLDATE,                -- event date\n",
    "        MonthYear,              -- month and year\n",
    "        EventCode,\n",
    "        EventBaseCode,\n",
    "        EventRootCode,\n",
    "        QuadClass,\n",
    "        GoldsteinScale,\n",
    "        Actor1Code,\n",
    "        Actor1Name,\n",
    "        Actor1CountryCode,\n",
    "        Actor1Type1Code,\n",
    "        Actor1Type2Code,\n",
    "        Actor1Type3Code,\n",
    "        Actor2Code,\n",
    "        Actor2Name,\n",
    "        Actor2CountryCode,\n",
    "        Actor2Type1Code,\n",
    "        Actor2Type2Code,\n",
    "        Actor2Type3Code,\n",
    "        ActionGeo_CountryCode,\n",
    "        ActionGeo_ADM1Code,\n",
    "        ActionGeo_Lat,\n",
    "        ActionGeo_Long,\n",
    "        ActionGeo_FeatureID,\n",
    "        NumArticles             -- target variable\n",
    "    FROM `gdelt-bq.gdeltv2.events`\n",
    "    WHERE SQLDATE >= {start_gdelt}  -- start date\n",
    "      AND SQLDATE <= {end_gdelt}    -- end date\n",
    "    ORDER BY RAND()                 -- order rows randomly to get random sample\n",
    "    LIMIT {limit}                   -- limit the number of rows to return\n",
    "    \"\"\"\n",
    "\n",
    "    # Always do a dry run first for cost estimation\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    dry_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    bytes_processed = dry_job.total_bytes_processed\n",
    "    estimated_cost = (bytes_processed / 1e12) * 5  # $5 per TB\n",
    "\n",
    "    print(\n",
    "        f\"Query will process: {bytes_processed:,} bytes \"\n",
    "        f\"({bytes_processed/1e6:.2f} MB) or rather \"\n",
    "        f\"({bytes_processed/1e9:.2f} GB).\"\n",
    "    )\n",
    "    print(f\"Estimated cost: ${estimated_cost:.6f}\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"Dry run complete - no data retrieved\")\n",
    "        return None\n",
    "\n",
    "    # Execute the actual query\n",
    "    print(\"Executing query...\")\n",
    "    df = pandas_gbq.read_gbq(query, project_id=client.project, dialect='standard')\n",
    "\n",
    "    print(f\"Query completed! Retrieved {len(df)} rows\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4f0a6",
   "metadata": {},
   "source": [
    "Get 10k random rows from GDELT events table from year 2024.\n",
    "\n",
    "I decided to go for a sample size 10k rows, because that should be an acceptable\n",
    "balance between speed of model training and showing it enough data.\n",
    "If I go for an 80:20 train:test split, I will end up with 8k rows for training\n",
    "and 2k rows for testing.\n",
    "There are just 24 features and one target variable.\n",
    "So basically the ration rows to features is 10000:24, which is 416.67.\n",
    "I intend to use tree based algorithms such as XGBoost, CatBoost and LightGBM.\n",
    "They are rather data efficient, and at this ratio, maybe it's even already\n",
    "enough for acceptable performance.\n",
    "\n",
    "Honestly, I could go for **much** more than that though, but then models would\n",
    "train much longer, too.\n",
    "This is some sort of a subset for speed of development.\n",
    "At the same time, I could have also gone for much less than that, but then it\n",
    "would definitely become a true subset, and whatever I train would likely be\n",
    "underperforming.\n",
    "So I decide to go with this as a compromise and check how well it performs.\n",
    "If it does good enough, I won't need to go for a larger subset.\n",
    "If it doesn't perform well, I can at least select hyperparameters and then go\n",
    "for a larger subset.\n",
    "Then again, this is not a machine learning engineering course, but a machine\n",
    "learning *operations*, so I don't need to get the best possible model in the\n",
    "first place.\n",
    "A good model is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc72812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with just a dry run to check costs\n",
    "test_df = safe_gdelt_query(\n",
    "    '2024-01-01',\n",
    "    '2024-12-31',\n",
    "    limit=14000,\n",
    "    dry_run=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks fine enough, so go for it\n",
    "# loads a pandas df into object data_gdelt\n",
    "\n",
    "# actually I just added this False as another layer of safety, so it doesn't\n",
    "# automatically run stuff\n",
    "# BigQuery can generate some costs, but at this rate it won't, because we're\n",
    "# still well below the free quota of 1TB per month\n",
    "if False:\n",
    "    data_gdelt = safe_gdelt_query(\n",
    "        '2024-01-01',\n",
    "        '2024-12-31',\n",
    "        limit=10000,\n",
    "        dry_run=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just have a look at if downloading worked\n",
    "data_gdelt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to parquet, so I can re-use it later without querying again\n",
    "data_gdelt.to_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_full.parquet\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b2504",
   "metadata": {},
   "source": [
    "# FIXME: CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfafa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from parquet again\n",
    "data_gdelt = pd.read_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_full.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a971c4",
   "metadata": {},
   "source": [
    "## Split data into train and test\n",
    "\n",
    "Split the data first to prevent data leakage.\n",
    "Make a truly unseen hold out test set, which will not be used for training or\n",
    "validation at all.\n",
    "It will only be used to evaluate one single final model in the very end.\n",
    "\n",
    "I will use a 80:20 split for training and testing.\n",
    "This will leave me with 8k rows for training and 2k rows for testing.\n",
    "For development, I will use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db388e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>...</th>\n",
       "      <th>Actor2CountryCode</th>\n",
       "      <th>Actor2Type1Code</th>\n",
       "      <th>Actor2Type2Code</th>\n",
       "      <th>Actor2Type3Code</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>20240328</td>\n",
       "      <td>202403</td>\n",
       "      <td>050</td>\n",
       "      <td>050</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>BUS</td>\n",
       "      <td>COMPANIES</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SO</td>\n",
       "      <td>SO</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>SO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>20240515</td>\n",
       "      <td>202405</td>\n",
       "      <td>040</td>\n",
       "      <td>040</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LEG</td>\n",
       "      <td>REPRESENTATIVES</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>FRA</td>\n",
       "      <td>GOV</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR00</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>-1456928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>20240405</td>\n",
       "      <td>202404</td>\n",
       "      <td>036</td>\n",
       "      <td>036</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ESP</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>GOV</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>SP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>20240209</td>\n",
       "      <td>202402</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>LEG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>USNC</td>\n",
       "      <td>35.6411</td>\n",
       "      <td>-79.84310</td>\n",
       "      <td>NC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>20240815</td>\n",
       "      <td>202408</td>\n",
       "      <td>042</td>\n",
       "      <td>042</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>TZA</td>\n",
       "      <td>TANZANIA</td>\n",
       "      <td>TZA</td>\n",
       "      <td>...</td>\n",
       "      <td>KEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>TZ</td>\n",
       "      <td>TZ</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>TZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "9254  20240328     202403       050           050            05          1   \n",
       "1561  20240515     202405       040           040            04          1   \n",
       "1670  20240405     202404       036           036            03          1   \n",
       "6087  20240209     202402       114           114            11          3   \n",
       "6669  20240815     202408       042           042            04          1   \n",
       "\n",
       "      GoldsteinScale Actor1Code       Actor1Name Actor1CountryCode  ...  \\\n",
       "9254             3.5        BUS        COMPANIES              None  ...   \n",
       "1561             1.0        LEG  REPRESENTATIVES              None  ...   \n",
       "1670             4.0        ESP            SPAIN               ESP  ...   \n",
       "6087            -2.0        USA   NORTH CAROLINA               USA  ...   \n",
       "6669             1.9        TZA         TANZANIA               TZA  ...   \n",
       "\n",
       "     Actor2CountryCode Actor2Type1Code Actor2Type2Code Actor2Type3Code  \\\n",
       "9254              None            None            None            None   \n",
       "1561               FRA             GOV            None            None   \n",
       "1670              None             GOV            None            None   \n",
       "6087              None             LEG            None            None   \n",
       "6669               KEN            None            None            None   \n",
       "\n",
       "     ActionGeo_CountryCode ActionGeo_ADM1Code ActionGeo_Lat ActionGeo_Long  \\\n",
       "9254                    SO                 SO        6.0000       48.00000   \n",
       "1561                    FR               FR00       48.8667        2.33333   \n",
       "1670                    SP                 SP       40.0000       -4.00000   \n",
       "6087                    US               USNC       35.6411      -79.84310   \n",
       "6669                    TZ                 TZ       -6.0000       35.00000   \n",
       "\n",
       "     ActionGeo_FeatureID NumArticles  \n",
       "9254                  SO           8  \n",
       "1561            -1456928           3  \n",
       "1670                  SP          10  \n",
       "6087                  NC           4  \n",
       "6669                  TZ           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test\n",
    "train_df, test_df = train_test_split(\n",
    "    data_gdelt,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# check the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27f0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both train and test data\n",
    "train_df.to_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "test_df.to_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_test.parquet\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f9878",
   "metadata": {},
   "source": [
    "Now I can work on the train split without risking leaking any information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6ab11",
   "metadata": {},
   "source": [
    "Check for missing values first. \n",
    "If there is any column that has a lot of missing values, I will drop it.\n",
    "Columns with just a low percentages may be imputed if there is a meaningful\n",
    "way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6091f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SQLDATE                  0.000000\n",
       "MonthYear                0.000000\n",
       "EventCode                0.000000\n",
       "EventBaseCode            0.000000\n",
       "EventRootCode            0.000000\n",
       "QuadClass                0.000000\n",
       "GoldsteinScale           0.000000\n",
       "Actor1Code               0.102375\n",
       "Actor1Name               0.102375\n",
       "Actor1CountryCode        0.460875\n",
       "Actor1Type1Code          0.551750\n",
       "Actor1Type2Code          0.975000\n",
       "Actor1Type3Code          0.999250\n",
       "Actor2Code               0.304250\n",
       "Actor2Name               0.304250\n",
       "Actor2CountryCode        0.566375\n",
       "Actor2Type1Code          0.671500\n",
       "Actor2Type2Code          0.983375\n",
       "Actor2Type3Code          0.999125\n",
       "ActionGeo_CountryCode    0.030625\n",
       "ActionGeo_ADM1Code       0.030625\n",
       "ActionGeo_Lat            0.032375\n",
       "ActionGeo_Long           0.031750\n",
       "ActionGeo_FeatureID      0.030625\n",
       "NumArticles              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "train_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794cb00",
   "metadata": {},
   "source": [
    "For most machine learning projects, it’s reasonable to drop columns with more \n",
    "than 50% missing values, especially if there are plenty of other features.\n",
    "High missingness usually means the feature will be hard to impute reliably and\n",
    "won’t add robust predictive power.\n",
    "\n",
    "Columns to drop:\n",
    "\t- Actor1Type2Code (97.5%)\n",
    "\t- Actor1Type3Code (99.9%)\n",
    "\t- Actor2Type2Code (98.3%)\n",
    "\t- Actor2Type3Code (99.9%)\n",
    "\t- Actor1Type1Code (55.2%)\n",
    "\t- Actor1CountryCode (46.1% — still too high for my taste, and difficult to impute)\n",
    "\t- Actor2CountryCode (56.6%)\n",
    "\t- Actor2Type1Code (67.2%)\n",
    "\n",
    "One option for imputation would be to use the mode or rather the most frequent\n",
    "value.\n",
    "However, this is data from global events.\n",
    "Imputation is always basically making up data and hoping it's a good guess.\n",
    "Often, for numerical data, a mean or median is a good guess.\n",
    "However, I am afraid in this case, it may not make much sense for some of the\n",
    "columns.\n",
    "For example, if the most frequent value is \"USA\", this will be filled in for\n",
    "all rows where the value is missing.\n",
    "But peprhaps there may be a good reason why the value is missing.\n",
    "For example, if the value is missing, it may mean that the event is not\n",
    "related to a country.\n",
    "Because of this, I will treat the missing values as missing by introducing a\n",
    "new category for unknown.\n",
    "I will have to check how they encode this in general and which value can be\n",
    "used for this.\n",
    "Perhaps 0 is a good value for this in case it is not taken for anything else.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7c174",
   "metadata": {},
   "source": [
    "The column \"SQLDATE\" is a date in the format YYYYMMDD.\n",
    "That integer is likely not very useful for modeling, so I will convert it to\n",
    "more informative features such as year, month, day of year, day of week, and\n",
    "whether it is a weekend or not.\n",
    "\n",
    "I will also drop the intermediate date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9446a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with roughly 50% or more missing values\n",
    "\n",
    "# define columns to drop\n",
    "columns_to_drop = [\n",
    "    \"Actor1Type2Code\",\n",
    "    \"Actor1Type3Code\",\n",
    "    \"Actor2Type2Code\",\n",
    "    \"Actor2Type3Code\",\n",
    "    \"Actor1Type1Code\",\n",
    "    \"Actor1CountryCode\",\n",
    "    \"Actor2CountryCode\",\n",
    "    \"Actor2Type1Code\"\n",
    "]\n",
    "\n",
    "# drop columns\n",
    "train_df = train_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7777a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8000 entries, 9254 to 7270\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   SQLDATE                8000 non-null   Int64  \n",
      " 1   MonthYear              8000 non-null   Int64  \n",
      " 2   EventCode              8000 non-null   object \n",
      " 3   EventBaseCode          8000 non-null   object \n",
      " 4   EventRootCode          8000 non-null   object \n",
      " 5   QuadClass              8000 non-null   Int64  \n",
      " 6   GoldsteinScale         8000 non-null   float64\n",
      " 7   Actor1Code             7181 non-null   object \n",
      " 8   Actor1Name             7181 non-null   object \n",
      " 9   Actor2Code             5566 non-null   object \n",
      " 10  Actor2Name             5566 non-null   object \n",
      " 11  ActionGeo_CountryCode  7755 non-null   object \n",
      " 12  ActionGeo_ADM1Code     7755 non-null   object \n",
      " 13  ActionGeo_Lat          7741 non-null   float64\n",
      " 14  ActionGeo_Long         7746 non-null   float64\n",
      " 15  ActionGeo_FeatureID    7755 non-null   object \n",
      " 16  NumArticles            8000 non-null   Int64  \n",
      "dtypes: Int64(4), float64(3), object(10)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>20240328</td>\n",
       "      <td>202403</td>\n",
       "      <td>050</td>\n",
       "      <td>050</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>BUS</td>\n",
       "      <td>COMPANIES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SO</td>\n",
       "      <td>SO</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>SO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>20240515</td>\n",
       "      <td>202405</td>\n",
       "      <td>040</td>\n",
       "      <td>040</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LEG</td>\n",
       "      <td>REPRESENTATIVES</td>\n",
       "      <td>FRAGOV</td>\n",
       "      <td>FRENCH</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR00</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>-1456928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>20240405</td>\n",
       "      <td>202404</td>\n",
       "      <td>036</td>\n",
       "      <td>036</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ESP</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>GOV</td>\n",
       "      <td>PRIME MINISTER</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>SP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>20240209</td>\n",
       "      <td>202402</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>LEG</td>\n",
       "      <td>CONGRESS</td>\n",
       "      <td>US</td>\n",
       "      <td>USNC</td>\n",
       "      <td>35.6411</td>\n",
       "      <td>-79.84310</td>\n",
       "      <td>NC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>20240815</td>\n",
       "      <td>202408</td>\n",
       "      <td>042</td>\n",
       "      <td>042</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>TZA</td>\n",
       "      <td>TANZANIA</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>TZ</td>\n",
       "      <td>TZ</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>TZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "9254  20240328     202403       050           050            05          1   \n",
       "1561  20240515     202405       040           040            04          1   \n",
       "1670  20240405     202404       036           036            03          1   \n",
       "6087  20240209     202402       114           114            11          3   \n",
       "6669  20240815     202408       042           042            04          1   \n",
       "\n",
       "      GoldsteinScale Actor1Code       Actor1Name Actor2Code      Actor2Name  \\\n",
       "9254             3.5        BUS        COMPANIES       None            None   \n",
       "1561             1.0        LEG  REPRESENTATIVES     FRAGOV          FRENCH   \n",
       "1670             4.0        ESP            SPAIN        GOV  PRIME MINISTER   \n",
       "6087            -2.0        USA   NORTH CAROLINA        LEG        CONGRESS   \n",
       "6669             1.9        TZA         TANZANIA        KEN         NAIROBI   \n",
       "\n",
       "     ActionGeo_CountryCode ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "9254                    SO                 SO         6.0000        48.00000   \n",
       "1561                    FR               FR00        48.8667         2.33333   \n",
       "1670                    SP                 SP        40.0000        -4.00000   \n",
       "6087                    US               USNC        35.6411       -79.84310   \n",
       "6669                    TZ                 TZ        -6.0000        35.00000   \n",
       "\n",
       "     ActionGeo_FeatureID  NumArticles  \n",
       "9254                  SO            8  \n",
       "1561            -1456928            3  \n",
       "1670                  SP           10  \n",
       "6087                  NC            4  \n",
       "6669                  TZ            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data again to get updated overview\n",
    "print(train_df.info())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fabb5",
   "metadata": {},
   "source": [
    "Column in need for imputation and strategy:\n",
    "- Actor1Code\n",
    "    - Dtype: object\n",
    "    - Example: \"USA\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- Actor1Name\n",
    "    - Dtype: object\n",
    "    - Example: \"NORTH CAROLINA\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- Actor2Code\n",
    "    - Dtype: object\n",
    "    - Example: \"GOV\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- Actor2Name\n",
    "    - Dtype: object\n",
    "    - Example: \"PRIME MINISTER\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- ActionGeo_CountryCode\n",
    "    - Dtype: object\n",
    "    - Example: \"FR\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- ActionGeo_ADM1Code\n",
    "    - Dtype:    object\n",
    "    - Example: \"FR00\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "- ActionGeo_FeatureID\n",
    "    - Dtype: object\n",
    "    - Example: \"TZ\"\n",
    "    - Strategy: Fill with \"UNKNOWN\"\n",
    "\n",
    "There are two more columns in need of imputation and strategy:\n",
    "ActionGeo_Lat and ActionGeo_Long, which are latitude and longitude of the event.\n",
    "\n",
    "Two options:\n",
    "- Impute with a value far outside the possible range (e.g., latitude 999,\n",
    "longitude 999) or with a special flag value (e.g., -999, if the ML library\n",
    "supports it).\n",
    "This makes it clear to the model and downstream analysis that location is\n",
    "missing—not just “somewhere ordinary.”\n",
    "- Alternatively, it would be possible to use the mean or median\n",
    "latitude/longitude, but this risks misleading the model to treat all\n",
    "missing-location events as if they happened in a single place, which is\n",
    "generally undesirable for geospatial modeling.\n",
    "\n",
    "I will go with the first option, so here's the plan:\n",
    "- ActionGeo_Lat\n",
    "    - Dtype: float64\n",
    "    - Example: 48.8667\n",
    "    - Strategy: Impute with 999\n",
    "- ActionGeo_Long\n",
    "    - Dtype: float64\n",
    "    - Example: 2.33333\n",
    "    - Strategy: Impute with 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ef81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLDATE                  0.0\n",
      "MonthYear                0.0\n",
      "EventCode                0.0\n",
      "EventBaseCode            0.0\n",
      "EventRootCode            0.0\n",
      "QuadClass                0.0\n",
      "GoldsteinScale           0.0\n",
      "Actor1Code               0.0\n",
      "Actor1Name               0.0\n",
      "Actor2Code               0.0\n",
      "Actor2Name               0.0\n",
      "ActionGeo_CountryCode    0.0\n",
      "ActionGeo_ADM1Code       0.0\n",
      "ActionGeo_Lat            0.0\n",
      "ActionGeo_Long           0.0\n",
      "ActionGeo_FeatureID      0.0\n",
      "NumArticles              0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>20240328</td>\n",
       "      <td>202403</td>\n",
       "      <td>050</td>\n",
       "      <td>050</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>BUS</td>\n",
       "      <td>COMPANIES</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>SO</td>\n",
       "      <td>SO</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>SO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>20240515</td>\n",
       "      <td>202405</td>\n",
       "      <td>040</td>\n",
       "      <td>040</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LEG</td>\n",
       "      <td>REPRESENTATIVES</td>\n",
       "      <td>FRAGOV</td>\n",
       "      <td>FRENCH</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR00</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>-1456928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>20240405</td>\n",
       "      <td>202404</td>\n",
       "      <td>036</td>\n",
       "      <td>036</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ESP</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>GOV</td>\n",
       "      <td>PRIME MINISTER</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>SP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>20240209</td>\n",
       "      <td>202402</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>LEG</td>\n",
       "      <td>CONGRESS</td>\n",
       "      <td>US</td>\n",
       "      <td>USNC</td>\n",
       "      <td>35.6411</td>\n",
       "      <td>-79.84310</td>\n",
       "      <td>NC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>20240815</td>\n",
       "      <td>202408</td>\n",
       "      <td>042</td>\n",
       "      <td>042</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>TZA</td>\n",
       "      <td>TANZANIA</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>TZ</td>\n",
       "      <td>TZ</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>TZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "9254  20240328     202403       050           050            05          1   \n",
       "1561  20240515     202405       040           040            04          1   \n",
       "1670  20240405     202404       036           036            03          1   \n",
       "6087  20240209     202402       114           114            11          3   \n",
       "6669  20240815     202408       042           042            04          1   \n",
       "\n",
       "      GoldsteinScale Actor1Code       Actor1Name Actor2Code      Actor2Name  \\\n",
       "9254             3.5        BUS        COMPANIES    UNKNOWN         UNKNOWN   \n",
       "1561             1.0        LEG  REPRESENTATIVES     FRAGOV          FRENCH   \n",
       "1670             4.0        ESP            SPAIN        GOV  PRIME MINISTER   \n",
       "6087            -2.0        USA   NORTH CAROLINA        LEG        CONGRESS   \n",
       "6669             1.9        TZA         TANZANIA        KEN         NAIROBI   \n",
       "\n",
       "     ActionGeo_CountryCode ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "9254                    SO                 SO         6.0000        48.00000   \n",
       "1561                    FR               FR00        48.8667         2.33333   \n",
       "1670                    SP                 SP        40.0000        -4.00000   \n",
       "6087                    US               USNC        35.6411       -79.84310   \n",
       "6669                    TZ                 TZ        -6.0000        35.00000   \n",
       "\n",
       "     ActionGeo_FeatureID  NumArticles  \n",
       "9254                  SO            8  \n",
       "1561            -1456928            3  \n",
       "1670                  SP           10  \n",
       "6087                  NC            4  \n",
       "6669                  TZ            1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values\n",
    "\n",
    "# define imputation strategy\n",
    "imputation_strategy = {\n",
    "    \"Actor1Code\": \"UNKNOWN\",\n",
    "    \"Actor1Name\": \"UNKNOWN\",\n",
    "    \"Actor2Code\": \"UNKNOWN\",\n",
    "    \"Actor2Name\": \"UNKNOWN\",\n",
    "    \"ActionGeo_CountryCode\": \"UNKNOWN\",\n",
    "    \"ActionGeo_ADM1Code\": \"UNKNOWN\",\n",
    "    \"ActionGeo_FeatureID\": \"UNKNOWN\",\n",
    "    \"ActionGeo_Lat\": 999,\n",
    "    \"ActionGeo_Long\": 999,\n",
    "}\n",
    "\n",
    "# fill missing values with new\n",
    "train_df.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "# check result\n",
    "print(train_df.isna().mean())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f721f7",
   "metadata": {},
   "source": [
    "Great! Now there are no missing values in the train_df.\n",
    "I hope that this method makes any sense.\n",
    "The only way to find out is to try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6eccd",
   "metadata": {},
   "source": [
    "## Take care of the columns for date\n",
    "\n",
    "There is a column called \"SQLDATE\" which is a date in the format YYYYMMDD.\n",
    "This is not very useful for modeling, so I will convert it to more informative\n",
    "features such as year, month, day of year, day of week, and whether it is a\n",
    "weekend or not.\n",
    "\n",
    "I will also drop the intermediate date column.\n",
    "\n",
    "Beyond this, there is a second column called \"MonthYear\" which seems to contain\n",
    "redundant information.\n",
    "It should probably be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b947918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime first\n",
    "train_df['date'] = pd.to_datetime(train_df['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "# Extract useful components\n",
    "train_df['year'] = train_df['date'].dt.year\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['day_of_year'] = train_df['date'].dt.dayofyear  # 1-365\n",
    "train_df['day_of_week'] = train_df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "train_df['is_weekend'] = train_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Drop the intermediate date column and the original date related columns\n",
    "train_df = train_df.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131b891",
   "metadata": {},
   "source": [
    "## Check if I need to One-Hot-Encode the categorical features\n",
    "\n",
    "Right now, many of the categorical columns use integers to encode the values.\n",
    "While this will probably work, it also introduces an order to the values.\n",
    "A model may learn some patterns from this that don't really exist.\n",
    "\n",
    "However, one-hot-encoding will increase the number of features by a lot.\n",
    "This may be a problem if the number of features is too high.\n",
    "\n",
    "Check which columns should not have an order and\n",
    "if one-hot-encoding is feasible here by having a look at the number of\n",
    "unique values in each column, then decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa3899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventCode                 169\n",
       "EventBaseCode             119\n",
       "EventRootCode              20\n",
       "QuadClass                   4\n",
       "GoldsteinScale             42\n",
       "Actor1Code                701\n",
       "Actor1Name               1191\n",
       "Actor2Code                605\n",
       "Actor2Name               1052\n",
       "ActionGeo_CountryCode     196\n",
       "ActionGeo_ADM1Code       1090\n",
       "ActionGeo_Lat            2118\n",
       "ActionGeo_Long           2204\n",
       "ActionGeo_FeatureID      2301\n",
       "NumArticles                30\n",
       "year                        1\n",
       "month                      12\n",
       "day_of_year               366\n",
       "day_of_week                 7\n",
       "is_weekend                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd0a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8000 entries, 9254 to 7270\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   EventCode              8000 non-null   object \n",
      " 1   EventBaseCode          8000 non-null   object \n",
      " 2   EventRootCode          8000 non-null   object \n",
      " 3   QuadClass              8000 non-null   Int64  \n",
      " 4   GoldsteinScale         8000 non-null   float64\n",
      " 5   Actor1Code             8000 non-null   object \n",
      " 6   Actor1Name             8000 non-null   object \n",
      " 7   Actor2Code             8000 non-null   object \n",
      " 8   Actor2Name             8000 non-null   object \n",
      " 9   ActionGeo_CountryCode  8000 non-null   object \n",
      " 10  ActionGeo_ADM1Code     8000 non-null   object \n",
      " 11  ActionGeo_Lat          8000 non-null   float64\n",
      " 12  ActionGeo_Long         8000 non-null   float64\n",
      " 13  ActionGeo_FeatureID    8000 non-null   object \n",
      " 14  NumArticles            8000 non-null   Int64  \n",
      " 15  year                   8000 non-null   int32  \n",
      " 16  month                  8000 non-null   int32  \n",
      " 17  day_of_year            8000 non-null   int32  \n",
      " 18  day_of_week            8000 non-null   int32  \n",
      " 19  is_weekend             8000 non-null   int64  \n",
      "dtypes: Int64(2), float64(3), int32(4), int64(1), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed600fe",
   "metadata": {},
   "source": [
    "Dang! Those are a lot of unique values in the categorical columns.\n",
    "The cardinality of these features is way too high for one-hot encoding, as it\n",
    "would blow up the feature space and hurt both memory and model generalization.\n",
    "\n",
    "So, instead, I will use native categorical encoding in the ML algorithms I aim\n",
    "to use: XGBoost, CatBoost, and LightGBM.\n",
    "- XGBoost, CatBoost, and LightGBM can handle categorical features by mapping\n",
    "them to integer codes (label encoding)\n",
    "- CatBoost/LightGBM even use more advanced target encoding under the hood.\n",
    "- Assign each unique category a unique integer, including `\"UNKNOWN\"` for missing\n",
    "values.\n",
    "\n",
    "Here's the plan:\n",
    "I will use the `OrdinalEncoder` from `sklearn` to encode the categorical columns.\n",
    "This is an encoder object that can be fitted on the training set, saved to a\n",
    "file, and then applied to train, test, and any new data, too.\n",
    "This is important as the encoding must be the same for train data and any new\n",
    "data the model is queried on, including the test data.\n",
    "If, on the other hand, the encoding is different, the model will not be able to\n",
    "make meaningful predictions.\n",
    "It also supports handling unknown values.\n",
    "For example, if there are categories in the test data that were not seen in the\n",
    "training data, the encoder will assign them a value of choice.\n",
    "I will use -1 for unknown values to signal the algorithm it's a new category it\n",
    "wasn't trained on.\n",
    "\n",
    "Usually, it would be important to save the encoder to a file.\n",
    "Here, however, I only develop the parts to get a rapid prototype and\n",
    "conceptualize.\n",
    "Once I made everything work, I will refactor and export this to a script.\n",
    "There, I will save the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1827af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>43.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>188.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>104.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>35.6411</td>\n",
       "      <td>-79.84310</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "9254       50.0           34.0            4.0          1             3.5   \n",
       "1561       43.0           27.0            3.0          1             1.0   \n",
       "1670       39.0           23.0            2.0          1             4.0   \n",
       "6087      104.0           71.0           10.0          3            -2.0   \n",
       "6669       45.0           29.0            3.0          1             1.9   \n",
       "\n",
       "      Actor1Code  Actor1Name  Actor2Code  Actor2Name  ActionGeo_CountryCode  \\\n",
       "9254        63.0       248.0       541.0       989.0                  160.0   \n",
       "1561       363.0       905.0       153.0       332.0                   58.0   \n",
       "1670       164.0      1006.0       182.0       758.0                  161.0   \n",
       "6087       621.0       775.0       316.0       201.0                  180.0   \n",
       "6669       601.0      1056.0       294.0       635.0                  175.0   \n",
       "\n",
       "      ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  ActionGeo_FeatureID  \\\n",
       "9254               793.0         6.0000        48.00000               2264.0   \n",
       "1561               253.0        48.8667         2.33333                188.0   \n",
       "1670               797.0        40.0000        -4.00000               2265.0   \n",
       "6087              1017.0        35.6411       -79.84310               2224.0   \n",
       "6669               884.0        -6.0000        35.00000               2279.0   \n",
       "\n",
       "      NumArticles  year  month  day_of_year  day_of_week  is_weekend  \n",
       "9254            8  2024      3           88            3           0  \n",
       "1561            3  2024      5          136            2           0  \n",
       "1670           10  2024      4           96            4           0  \n",
       "6087            4  2024      2           40            4           0  \n",
       "6669            1  2024      8          228            3           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the categorical columns\n",
    "categorical_cols = [\n",
    "    'EventCode',\n",
    "    'EventBaseCode',\n",
    "    'EventRootCode',\n",
    "    'Actor1Code',\n",
    "    'Actor1Name',\n",
    "    'Actor2Code',\n",
    "    'Actor2Name',\n",
    "    'ActionGeo_CountryCode',\n",
    "    'ActionGeo_ADM1Code',\n",
    "    'ActionGeo_FeatureID'\n",
    "]\n",
    "\n",
    "# initialize an encoder for categorical data\n",
    "# encodes categorical data as integers (example \"USA\" may get 1 or whatever)\n",
    "# use -1 for unknown values to signal algorithm it's a new category it wasn't trained on\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit encoder on train set and transform it right away\n",
    "train_df[categorical_cols] = encoder.fit_transform(train_df[categorical_cols])\n",
    "\n",
    "# check the result\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32afb927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.196500</td>\n",
       "      <td>43.704875</td>\n",
       "      <td>5.925875</td>\n",
       "      <td>1.813375</td>\n",
       "      <td>0.471487</td>\n",
       "      <td>363.219875</td>\n",
       "      <td>703.471750</td>\n",
       "      <td>369.439625</td>\n",
       "      <td>699.038500</td>\n",
       "      <td>122.176750</td>\n",
       "      <td>626.614875</td>\n",
       "      <td>63.724785</td>\n",
       "      <td>35.278839</td>\n",
       "      <td>1482.922250</td>\n",
       "      <td>5.6105</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>6.388125</td>\n",
       "      <td>179.621500</td>\n",
       "      <td>2.706250</td>\n",
       "      <td>0.194250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.814056</td>\n",
       "      <td>33.158543</td>\n",
       "      <td>5.560777</td>\n",
       "      <td>1.132456</td>\n",
       "      <td>4.801816</td>\n",
       "      <td>206.078193</td>\n",
       "      <td>362.997321</td>\n",
       "      <td>186.551957</td>\n",
       "      <td>321.558717</td>\n",
       "      <td>57.680394</td>\n",
       "      <td>334.660121</td>\n",
       "      <td>172.290927</td>\n",
       "      <td>188.447514</td>\n",
       "      <td>753.310752</td>\n",
       "      <td>4.907347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.436599</td>\n",
       "      <td>105.059388</td>\n",
       "      <td>1.865113</td>\n",
       "      <td>0.395647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-45.250000</td>\n",
       "      <td>-176.533000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>27.833300</td>\n",
       "      <td>-73.966200</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>347.500000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.768000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1689.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>1108.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>977.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>46.772800</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "count  8000.000000    8000.000000    8000.000000     8000.0     8000.000000   \n",
       "mean     63.196500      43.704875       5.925875   1.813375        0.471487   \n",
       "std      47.814056      33.158543       5.560777   1.132456        4.801816   \n",
       "min       0.000000       0.000000       0.000000        1.0      -10.000000   \n",
       "25%      39.000000      23.000000       2.000000        1.0       -2.000000   \n",
       "50%      49.000000      33.000000       3.000000        1.0        1.000000   \n",
       "75%      96.000000      67.000000      10.000000        3.0        3.400000   \n",
       "max     168.000000     118.000000      19.000000        4.0       10.000000   \n",
       "\n",
       "        Actor1Code   Actor1Name   Actor2Code   Actor2Name  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean    363.219875   703.471750   369.439625   699.038500   \n",
       "std     206.078193   362.997321   186.551957   321.558717   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%     193.000000   405.000000   182.000000   434.000000   \n",
       "50%     347.500000   768.000000   456.000000   810.000000   \n",
       "75%     608.000000  1108.000000   541.000000   989.000000   \n",
       "max     700.000000  1190.000000   604.000000  1051.000000   \n",
       "\n",
       "       ActionGeo_CountryCode  ActionGeo_ADM1Code  ActionGeo_Lat  \\\n",
       "count            8000.000000         8000.000000    8000.000000   \n",
       "mean              122.176750          626.614875      63.724785   \n",
       "std                57.680394          334.660121     172.290927   \n",
       "min                 0.000000            0.000000     -45.250000   \n",
       "25%                82.000000          362.000000      27.833300   \n",
       "50%               140.000000          652.000000      37.768000   \n",
       "75%               179.000000          977.000000      47.000000   \n",
       "max               195.000000         1089.000000     999.000000   \n",
       "\n",
       "       ActionGeo_Long  ActionGeo_FeatureID  NumArticles    year        month  \\\n",
       "count     8000.000000          8000.000000       8000.0  8000.0  8000.000000   \n",
       "mean        35.278839          1482.922250       5.6105  2024.0     6.388125   \n",
       "std        188.447514           753.310752     4.907347     0.0     3.436599   \n",
       "min       -176.533000             0.000000          1.0  2024.0     1.000000   \n",
       "25%        -73.966200           852.000000          2.0  2024.0     3.000000   \n",
       "50%         21.000000          1689.500000          4.0  2024.0     6.000000   \n",
       "75%         46.772800          2181.000000         10.0  2024.0     9.000000   \n",
       "max        999.000000          2300.000000        140.0  2024.0    12.000000   \n",
       "\n",
       "       day_of_year  day_of_week   is_weekend  \n",
       "count  8000.000000  8000.000000  8000.000000  \n",
       "mean    179.621500     2.706250     0.194250  \n",
       "std     105.059388     1.865113     0.395647  \n",
       "min       1.000000     0.000000     0.000000  \n",
       "25%      87.000000     1.000000     0.000000  \n",
       "50%     177.000000     3.000000     0.000000  \n",
       "75%     271.000000     4.000000     0.000000  \n",
       "max     366.000000     6.000000     1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of these new values\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5daef94",
   "metadata": {},
   "source": [
    "## No scaling or normalization is needed\n",
    "\n",
    "The range of the features differs a lot.\n",
    "For example, `QuadClass` ranges from 1 to 4, while `ActionGeo_FeatureID` ranges\n",
    "from 0 to 2300.\n",
    "Many algorithms would suffer from this.\n",
    "\n",
    "However, I already decided to use tree-based models only.\n",
    "This is actually for a personal reason.\n",
    "I will have to use these algorithms for a different project in the future, so I\n",
    "already want to gather some experience and get familiar with them.\n",
    "\n",
    "Tree-based models like XGBoost, CatBoost, and LightGBM do not require feature\n",
    "scaling or normalization for either categorical features (integer encoded) or\n",
    "numerical features.\n",
    "\n",
    "These algorithms split data based on feature values and thresholds, not on\n",
    "Euclidean distance, so scaling has no effect on their performance or accuracy.\n",
    "\n",
    "Label-encoded categorical variables are treated as distinct categories,\n",
    "regardless of their actual integer value range.\n",
    "\n",
    "The models can be trained directly with the current integer and numeric features.\n",
    "\n",
    "If I had used different algorithms, I would have to check if scaling or\n",
    "normalization is needed.\n",
    "Here, however, this is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03c60d",
   "metadata": {},
   "source": [
    "## Divide into features and target\n",
    "\n",
    "What's left now is to extract the features and the target.\n",
    "The target is the number of articles in the media `NumArticles`.\n",
    "The features are all the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1d3984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>43.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>104.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>35.6411</td>\n",
       "      <td>-79.84310</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "9254       50.0           34.0            4.0          1             3.5   \n",
       "1561       43.0           27.0            3.0          1             1.0   \n",
       "1670       39.0           23.0            2.0          1             4.0   \n",
       "6087      104.0           71.0           10.0          3            -2.0   \n",
       "6669       45.0           29.0            3.0          1             1.9   \n",
       "\n",
       "      Actor1Code  Actor1Name  Actor2Code  Actor2Name  ActionGeo_CountryCode  \\\n",
       "9254        63.0       248.0       541.0       989.0                  160.0   \n",
       "1561       363.0       905.0       153.0       332.0                   58.0   \n",
       "1670       164.0      1006.0       182.0       758.0                  161.0   \n",
       "6087       621.0       775.0       316.0       201.0                  180.0   \n",
       "6669       601.0      1056.0       294.0       635.0                  175.0   \n",
       "\n",
       "      ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  ActionGeo_FeatureID  \\\n",
       "9254               793.0         6.0000        48.00000               2264.0   \n",
       "1561               253.0        48.8667         2.33333                188.0   \n",
       "1670               797.0        40.0000        -4.00000               2265.0   \n",
       "6087              1017.0        35.6411       -79.84310               2224.0   \n",
       "6669               884.0        -6.0000        35.00000               2279.0   \n",
       "\n",
       "      year  month  day_of_year  day_of_week  is_weekend  \n",
       "9254  2024      3           88            3           0  \n",
       "1561  2024      5          136            2           0  \n",
       "1670  2024      4           96            4           0  \n",
       "6087  2024      2           40            4           0  \n",
       "6669  2024      8          228            3           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features and check result\n",
    "X_train = train_df.drop(columns=[\"NumArticles\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d6583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9254     8\n",
       "1561     3\n",
       "1670    10\n",
       "6087     4\n",
       "6669     1\n",
       "Name: NumArticles, dtype: Int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target and check resuls\n",
    "y_train = train_df[\"NumArticles\"]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378f060",
   "metadata": {},
   "source": [
    "Amazing! I'd say everything looks great.\n",
    "This should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b0f59",
   "metadata": {},
   "source": [
    "## Collect the steps and refactor them into a function\n",
    "\n",
    "This exact same logic must be applied to the test_df, too, so the model will be\n",
    "able to make meaningful predictions.\n",
    "\n",
    "I will collect the steps and refactor them into a function.\n",
    "This function can not only be used for the test_df, but it will also be useful\n",
    "for later when I export this notebook as a script.\n",
    "\n",
    "Make sure to use the train_df and then apply whatever it learned to the test_df.\n",
    "Never learn from the full dataset or from the test_df itself.\n",
    "An example for this is checking number of missing values to decide which columns\n",
    "to drop and scaling the data in case it is needed.\n",
    "\n",
    "Make sure to fit encoding (like category codes) on the training set, then apply\n",
    "to the test set to avoid data leakage.\n",
    "\n",
    "Make sure train and test columns are in the same order.\n",
    "\n",
    "Save the data to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "446b02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECTION OF STEPS\n",
    "# FIXME: TURN THIS INTO A FUNCTION\n",
    "# IT MUST TAKE A DATA SET\n",
    "# INFO IF IT IS TRAIN OR TEST\n",
    "# DEPENDING ON WHICH SPLIT IT IS, DO DIFFERENT THINGS\n",
    "# TRAIN: FITS AND SAVES AND OPTIMALLY LOGS AN ENCODER\n",
    "# TEST OR RATHER JUST NOT TRAIN: TAKES / LOADS THE ENCODER AND JUST APPLIES IT TO THE DATA\n",
    "# RETURN FEATURES AND LABELS\n",
    "\n",
    "def save_series_as_parquet(series, filepath):\n",
    "    \"\"\"Save a pandas Series as parquet file\"\"\"\n",
    "    # Convert Series to DataFrame with proper column name\n",
    "    df = series.to_frame(name=series.name if series.name else 'target')\n",
    "    df.to_parquet(filepath)\n",
    "\n",
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    is_train: bool,\n",
    "    encoder: Optional[OrdinalEncoder] = None,\n",
    "    encoder_path: Optional[str] = None,\n",
    "    save_data: bool = False,\n",
    "    save_path_dir: Optional[str] = None,\n",
    "    path_repo: Optional[str] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training or testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constants\n",
    "\n",
    "    # define columns to drop\n",
    "    columns_to_drop = [\n",
    "        \"Actor1Type2Code\",\n",
    "        \"Actor1Type3Code\",\n",
    "        \"Actor2Type2Code\",\n",
    "        \"Actor2Type3Code\",\n",
    "        \"Actor1Type1Code\",\n",
    "        \"Actor1CountryCode\",\n",
    "        \"Actor2CountryCode\",\n",
    "        \"Actor2Type1Code\"\n",
    "    ]\n",
    "\n",
    "    # define imputation strategy for columns with missing values\n",
    "    imputation_strategy = {\n",
    "        \"Actor1Code\": \"UNKNOWN\",\n",
    "        \"Actor1Name\": \"UNKNOWN\",\n",
    "        \"Actor2Code\": \"UNKNOWN\",\n",
    "        \"Actor2Name\": \"UNKNOWN\",\n",
    "        \"ActionGeo_CountryCode\": \"UNKNOWN\",\n",
    "        \"ActionGeo_ADM1Code\": \"UNKNOWN\",\n",
    "        \"ActionGeo_FeatureID\": \"UNKNOWN\",\n",
    "        \"ActionGeo_Lat\": 999,\n",
    "        \"ActionGeo_Long\": 999,\n",
    "    }\n",
    "\n",
    "    # define the categorical columns for encoding\n",
    "    categorical_cols = [\n",
    "        'EventCode',\n",
    "        'EventBaseCode',\n",
    "        'EventRootCode',\n",
    "        'Actor1Code',\n",
    "        'Actor1Name',\n",
    "        'Actor2Code',\n",
    "        'Actor2Name',\n",
    "        'ActionGeo_CountryCode',\n",
    "        'ActionGeo_ADM1Code',\n",
    "        'ActionGeo_FeatureID'\n",
    "    ]\n",
    "    \n",
    "    # target value or rather label\n",
    "    target_label = \"NumArticles\"\n",
    "    \n",
    "    # path to intermediate data\n",
    "    if save_data == True:\n",
    "        PATH_DATA = Path(path_repo) / \"data/intermediate\"\n",
    "\n",
    "\n",
    "    # Handle missing values\n",
    "    # drop columns with roughly 50% or more missing values\n",
    "    # at some point, imputation doesn't make sense anymore, so drop them\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # impute missing values with new category for unknown\n",
    "    df.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "\n",
    "    # Handle time and data columns\n",
    "    # convert column \"SQLDATE\" to more meaningful date and time info\n",
    "    # this will allos models to learn from it better\n",
    "\n",
    "    # convert to datetime first\n",
    "    df['date'] = pd.to_datetime(df['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "    # extract useful components\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear  # 1-365\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # drop the intermediate date column and the original date related columns\n",
    "    df = df.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)\n",
    "\n",
    "\n",
    "    # Handle categorical data by numerical encoding\n",
    "    \n",
    "    # if train data is passed, fit_transform and save encoder\n",
    "    if is_train == True:\n",
    "        \n",
    "        # initialize an encoder for categorical data\n",
    "        # encodes categorical data as integers\n",
    "        # example \"USA\" may get 1 or whatever\n",
    "        # use -1 for unknown values\n",
    "        # this signals algorithm it's a new category it wasn't trained on\n",
    "        encoder = OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        )\n",
    "        \n",
    "        # fit encoder on train set and transform data it right away\n",
    "        df[categorical_cols] = encoder.fit_transform(df[categorical_cols])\n",
    "        \n",
    "        # if data is supposed to be saved, save encoder to file\n",
    "        if save_data == True:\n",
    "            encoder_path = 'ordinal_encoder_prototype.pkl' \n",
    "            joblib.dump(encoder, encoder_path)\n",
    "\n",
    "            # log as part of a custom model (for later use with ML model)\n",
    "            with mlflow.start_run():\n",
    "                # log just the encoder as artifact for now\n",
    "                mlflow.log_artifact(encoder_path, artifact_path='preprocessing')\n",
    "\n",
    "                # clean up local file after logging\n",
    "                # so it's in just one location: artifact store\n",
    "                os.remove(encoder_path)\n",
    "\n",
    "\n",
    "    # if test data is passed, load the encoder and transform test data\n",
    "    elif is_train == False:\n",
    "        \n",
    "        # we need the run_id to locate the encoder in the artifact store\n",
    "        if encoder is None and encoder_path is None:\n",
    "            raise ValueError(\"For test data, either 'encoder' object or 'encoder_path' (run_id) must be provided\")\n",
    "        \n",
    "        # if encoder object is passed directly, use it\n",
    "        if encoder is not None:\n",
    "            loaded_encoder = encoder\n",
    "        \n",
    "        # if encoder_path (run_id) is provided, load from artifact store\n",
    "        elif encoder_path is not None:\n",
    "            # download the encoder from MLflow artifact store\n",
    "            # encoder_path should be the run_id where the encoder was logged\n",
    "            artifact_path = mlflow.artifacts.download_artifacts(\n",
    "                f\"runs:/{encoder_path}/preprocessing/ordinal_encoder_prototype.pkl\"\n",
    "            )\n",
    "            # load the encoder from the downloaded file\n",
    "            loaded_encoder = joblib.load(artifact_path)\n",
    "            \n",
    "            # clean up: delete the temporary downloaded file\n",
    "            os.remove(artifact_path)\n",
    "        \n",
    "        # apply the loaded encoder to transform test data (only transform, no fitting)\n",
    "        df[categorical_cols] = loaded_encoder.transform(df[categorical_cols])\n",
    "\n",
    "\n",
    "    # Extract features and labels\n",
    "    # get features\n",
    "    X = df.drop(columns=[target_label])\n",
    "\n",
    "    # get target\n",
    "    y = df[target_label]\n",
    "    \n",
    "    \n",
    "    # Save data to parquet files if desired\n",
    "    if save_data == True:\n",
    "        \n",
    "        # ensure the intermediate data directory exists\n",
    "        PATH_DATA.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # if path to directory to save data to was passed, use it\n",
    "        if save_path_dir is not None:\n",
    "            save_name = PATH_DATA / save_path_dir\n",
    "        # if not passed, use a default path\n",
    "        else:\n",
    "            # count number of directories in intermediate data dir\n",
    "            num_dirs = sum(1 for p in PATH_DATA.iterdir() if p.is_dir())\n",
    "            save_name = PATH_DATA / f\"gdelt_events_2024_subset_version_{num_dirs}\"\n",
    "            \n",
    "        # ensure the save directory exists\n",
    "        save_name.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # switch between train and test features and labels\n",
    "        if is_train == True:\n",
    "            X_name = \"X_train\"\n",
    "            y_name = \"y_train\"\n",
    "        else:\n",
    "            X_name = \"X_test\"\n",
    "            y_name = \"y_test\"\n",
    "            \n",
    "        # save data to parquet files\n",
    "        X.to_parquet(save_name / f\"{X_name}.parquet\")\n",
    "        save_series_as_parquet(y, save_name / f\"{y_name}.parquet\")\n",
    "\n",
    "    # always return features and labels\n",
    "    # return encoder if train was used\n",
    "    if is_train == True:\n",
    "        return X, y, encoder\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425c8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of previously processed train data to compare if output is same\n",
    "train_df_backup = train_df.copy()\n",
    "X_train_backup = X_train.copy()\n",
    "y_train_backup = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4833d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# briefly check if backup worked\n",
    "print(train_df_backup.equals(train_df))\n",
    "print(X_train_backup.equals(X_train))\n",
    "print(y_train_backup.equals(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aa803da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data again fresh from file, because it was already processed\n",
    "train_df = pd.read_parquet(PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1558459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = train_df,\n",
    "    is_train = True,\n",
    "    save_data = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d502b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names comparison:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True]\n",
      "\n",
      "Value comparison:\n",
      "X values equal: True\n",
      "y values equal: True\n",
      "\n",
      "Index comparison:\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# compare column names\n",
    "print(\"Column names comparison:\")\n",
    "print(X_train_backup.columns == X_train_new.columns)\n",
    "\n",
    "\n",
    "# compare values element by element (ignoring index/column names)\n",
    "print(\"\\nValue comparison:\")\n",
    "print(f\"X values equal: {X_train_new.values.shape == X_train_backup.values.shape and (X_train_new.values == X_train_backup.values).all()}\")\n",
    "print(f\"y values equal: {y_train_new.values.shape == y_train_backup.values.shape and (y_train_new.values == y_train_backup.values).all()}\")\n",
    "\n",
    "# compare index now\n",
    "print(\"\\nIndex comparison:\")\n",
    "print(X_train_new.index == X_train_backup.index)\n",
    "print(y_train_new.index == y_train_backup.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fae3d8",
   "metadata": {},
   "source": [
    "Great! The **actual** data in there is the same.\n",
    "All column names match and the values are the same, too for both features (X)\n",
    "and the labels (y).\n",
    "The index differs, but this is expected, so it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea2d46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for test data\n",
    "# pass the new encoder here\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = test_df,\n",
    "    is_train = False,\n",
    "    save_data = False,\n",
    "    encoder = encoder_new\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2784b",
   "metadata": {},
   "source": [
    "I'll now also check this function for the test data.\n",
    "It's bad to look at test data, but I guess verifying the code works by\n",
    "comparing columns and printing the head is acceptable.\n",
    "Without it, I wouldn't even know if my function works.\n",
    "\n",
    "In theory, I could also just run it in `is_train = False` mode for the train\n",
    "data, but I want to be completely sure.\n",
    "\n",
    "Honestly, this cannot be seen as data leakage, because I will obtain like zero\n",
    "information from looking at these numbers.\n",
    "To make this even more clear, I'll just print the first row.\n",
    "This is just enough for me to see the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c4d9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing columns:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>88.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "6252       88.0           63.0            9.0          3            -5.0   \n",
       "\n",
       "      Actor1Code  Actor1Name  Actor2Code  Actor2Name  ActionGeo_CountryCode  \\\n",
       "6252       193.0      1117.0       541.0       989.0                  177.0   \n",
       "\n",
       "      ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  ActionGeo_FeatureID  \\\n",
       "6252               892.0           54.0            -4.0               2281.0   \n",
       "\n",
       "      year  month  day_of_year  day_of_week  is_weekend  \n",
       "6252  2024      2           36            0           0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare columns to backup -> columns must match\n",
    "print(\"Comparing columns:\")\n",
    "print(X_test_new.columns == X_train_backup.columns)\n",
    "\n",
    "# print only first row to get some feedback if function works\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9954d94",
   "metadata": {},
   "source": [
    "Amazing! This can be used!\n",
    "\n",
    "But I need to test the writing function.\n",
    "This will also log to MLFLow, so there are many more break points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47d96c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run rumbling-gull-895 at: http://127.0.0.1:5001/#/experiments/1/runs/c20dd06ff0e74c0aa45621b4fb7dbfa7\n",
      "🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = train_df,\n",
    "    is_train = True,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b684d",
   "metadata": {},
   "source": [
    "Great! This works!\n",
    "The data is saved and the encoder is logged to MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00c3cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for test data\n",
    "# pass run ID as encoder path\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = test_df,\n",
    "    is_train = False,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO,\n",
    "    encoder_path = \"c20dd06ff0e74c0aa45621b4fb7dbfa7\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c8ea504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>88.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "6252       88.0           63.0            9.0          3            -5.0   \n",
       "\n",
       "      Actor1Code  Actor1Name  Actor2Code  Actor2Name  ActionGeo_CountryCode  \\\n",
       "6252       193.0      1117.0       541.0       989.0                  177.0   \n",
       "\n",
       "      ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  ActionGeo_FeatureID  \\\n",
       "6252               892.0           54.0            -4.0               2281.0   \n",
       "\n",
       "      year  month  day_of_year  day_of_week  is_weekend  \n",
       "6252  2024      2           36            0           0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to first row of previous run\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771bf2e",
   "metadata": {},
   "source": [
    "Amazing! This works, too! So, this is my data prep and I can go on I think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499f1bd",
   "metadata": {},
   "source": [
    "I leave some code here for later reference.\n",
    "\n",
    "I haven't verified this works yet, but this is how I can likely do it:\n",
    "\n",
    "```python\n",
    "# bundle a model witht the encoder\n",
    "mlflow.pyfunc.log_model(\"model_with_preprocessing\",\n",
    "                        python_model=YourModelWrapper(),\n",
    "                        artifacts={'encoder': encoder_path})\n",
    "\n",
    "# load the encoder in future scripts/notebooks\n",
    "# if this is actually needed, because I have the function\n",
    "run_id = \"<your_run_id>\"\n",
    "encoder_path = mlflow.artifacts.download_artifacts(f\"runs/{run_id}/preprocessing/ordinal_encoder.pkl\")\n",
    "loaded_encoder = joblib.load(encoder_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c68ee",
   "metadata": {},
   "source": [
    "## Get a 1000 Samples Subset from Processed Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192aad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a31780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac43ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00cc54cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
