{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b470433c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "In this notebook, I have a look at the data I downloaded from BigQuery.\n",
    "I already split the data into train and test sets right away in the script for\n",
    "downloading the data to prevent a data leakage.\n",
    "\n",
    "Here, I will inspect the train split and see what needs to be done to prepare\n",
    "it for modeling.\n",
    "I will perform the scripts, then collect them in a function and apply it to the\n",
    "test split, too.\n",
    "Whatever decisions need to be made will be based on the train split exclusively.\n",
    "Nothing will be decided based on the test split.\n",
    "In case dataset wide statistics are needed for some transformation, they will\n",
    "be based on the train split exclusively, too, and later applied to the test\n",
    "split.\n",
    "\n",
    "The workflow from this note will be exported to the script\n",
    "`scripts/prepare_data_for_modeling.py`.\n",
    "\n",
    "## Environment\n",
    "\n",
    "To use this project's uv environment, make sure you installed it according to\n",
    "the instructions in the README.md file.\n",
    "\n",
    "Then, connect to the `.venv` kernel.\n",
    "Check the path to the kernel to make sure it's the right one.\n",
    "It should be `.venv/bin/python`.\n",
    "\n",
    "Run the next cell to check if you use the correct kernel.\n",
    "It should output this:\n",
    "\n",
    "```\n",
    "<path_to_wherever_you_cloned_the_repo_to>/gdelt-newsimpact/.venv/bin/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f6eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fakrueg/projects/courses/datatalks/mlops-zoomcamp/mlopsproject2/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9268f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f324b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import joblib\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "PATH_REPO = Path(\".\").resolve().parent\n",
    "PATH_DATA = PATH_REPO / \"data\" / \"raw\"\n",
    "PATH_TRAIN = PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\"\n",
    "PATH_TEST = PATH_DATA / \"gdelt_events_2024_subset_10k_test.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec1866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1755520214526, experiment_id='4', last_update_time=1755520214526, lifecycle_stage='active', name='testing_setup', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for saving any feature scalers or encoders to the artifact store\n",
    "\n",
    "# set MLFlow tracking URI or rather: basically connect to the MLFlow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# set experiment\n",
    "mlflow.set_experiment(\"testing_setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfafa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>MIL</td>\n",
       "      <td>COMMANDER</td>\n",
       "      <td>None</td>\n",
       "      <td>RS</td>\n",
       "      <td>50.6107</td>\n",
       "      <td>36.5802</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UKRAINIAN</td>\n",
       "      <td>UKR</td>\n",
       "      <td>RS</td>\n",
       "      <td>55.7522</td>\n",
       "      <td>37.6156</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>CVL</td>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>None</td>\n",
       "      <td>JO</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>UKRGOV</td>\n",
       "      <td>KIEV</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UP</td>\n",
       "      <td>50.4333</td>\n",
       "      <td>30.5167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SP</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "0  20241107     202411       180           180            18          4   \n",
       "1  20240922     202409       190           190            19          4   \n",
       "2  20241107     202411       180           180            18          4   \n",
       "3  20240922     202409       190           190            19          4   \n",
       "4  20240922     202409       190           190            19          4   \n",
       "\n",
       "   GoldsteinScale Actor1Code Actor1Name Actor1CountryCode  \\\n",
       "0            -9.0        MIL  COMMANDER              None   \n",
       "1           -10.0        UKR  UKRAINIAN               UKR   \n",
       "2            -9.0        CVL  COMMUNITY              None   \n",
       "3           -10.0     UKRGOV       KIEV               UKR   \n",
       "4           -10.0       None       None              None   \n",
       "\n",
       "  ActionGeo_CountryCode  ActionGeo_Lat  ActionGeo_Long  NumArticles  \n",
       "0                    RS        50.6107         36.5802           10  \n",
       "1                    RS        55.7522         37.6156            4  \n",
       "2                    JO        31.0000         36.0000           10  \n",
       "3                    UP        50.4333         30.5167            1  \n",
       "4                    SP        28.0000        -15.5000            4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from parquet files\n",
    "\n",
    "# train data\n",
    "df_train = pd.read_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\"\n",
    ")\n",
    "\n",
    "# test data\n",
    "df_test = pd.read_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_test.parquet\"\n",
    ")\n",
    "\n",
    "# have a look at the train data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6ab11",
   "metadata": {},
   "source": [
    "## Check for Missing Values\n",
    "\n",
    "If there is any column that has a lot of missing values, I will drop it.\n",
    "Columns with just a low percentages may be imputed if there is a meaningful\n",
    "way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6091f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value rates:\n",
      "SQLDATE                  0.000000\n",
      "MonthYear                0.000000\n",
      "EventCode                0.000000\n",
      "EventBaseCode            0.000000\n",
      "EventRootCode            0.000000\n",
      "QuadClass                0.000000\n",
      "GoldsteinScale           0.000000\n",
      "Actor1Code               0.099875\n",
      "Actor1Name               0.099875\n",
      "Actor1CountryCode        0.391750\n",
      "ActionGeo_CountryCode    0.030250\n",
      "ActionGeo_Lat            0.031125\n",
      "ActionGeo_Long           0.031125\n",
      "NumArticles              0.000000\n",
      "dtype: float64\n",
      "\n",
      "Columns with >= 50% missing values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for missing values and extract columns with >= 50% missing\n",
    "missing_rates = df_train.isnull().mean()\n",
    "columns_high_missing = missing_rates[missing_rates >= 0.5].index.tolist()\n",
    "\n",
    "print(\"Missing value rates:\")\n",
    "print(missing_rates)\n",
    "print(f\"\\nColumns with >= 50% missing values:\")\n",
    "print(columns_high_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794cb00",
   "metadata": {},
   "source": [
    "For most machine learning projects, it’s reasonable to drop columns with more \n",
    "than 50% missing values, especially if there are plenty of other features.\n",
    "High missingness usually means the feature will be hard to impute reliably and\n",
    "won’t add robust predictive power.\n",
    "\n",
    "One option for imputation would be to use the mode or rather the most frequent\n",
    "value.\n",
    "However, this is data from global events.\n",
    "Imputation is always basically making up data and hoping it's a good guess.\n",
    "Often, for numerical data, a mean or median is a good guess.\n",
    "However, I am afraid in this case, it may not make much sense for some of the\n",
    "columns.\n",
    "For example, if the most frequent value is \"USA\", this will be filled in for\n",
    "all rows where the value is missing.\n",
    "But perhaps there may be a good reason why the value is missing.\n",
    "For example, if the value is missing, it may mean that the event is not\n",
    "related to a country.\n",
    "Because of this, I will treat the missing values as missing by introducing a\n",
    "new category for unknown.\n",
    "I will have to check how they encode this in general and which value can be\n",
    "used for this.\n",
    "Perhaps 0 is a good value for this in case it is not taken for anything else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9446a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns to drop\n",
      "\n",
      "Missing value rates:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SQLDATE                  0.000000\n",
       "MonthYear                0.000000\n",
       "EventCode                0.000000\n",
       "EventBaseCode            0.000000\n",
       "EventRootCode            0.000000\n",
       "QuadClass                0.000000\n",
       "GoldsteinScale           0.000000\n",
       "Actor1Code               0.099875\n",
       "Actor1Name               0.099875\n",
       "Actor1CountryCode        0.391750\n",
       "ActionGeo_CountryCode    0.030250\n",
       "ActionGeo_Lat            0.031125\n",
       "ActionGeo_Long           0.031125\n",
       "NumArticles              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print columns that will be dropped\n",
    "if len(columns_high_missing) > 0:\n",
    "    print(\"Columns that will be dropped:\")\n",
    "    for column in columns_high_missing:\n",
    "        print(column)\n",
    "    # drop columns with 50% or more missing values\n",
    "    df_train = df_train.drop(columns=columns_high_missing)\n",
    "else:\n",
    "    print(\"No columns to drop\")\n",
    "\n",
    "# check for missing values again get an updated overview\n",
    "print(\"\\nMissing value rates:\")\n",
    "df_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03c2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   SQLDATE                8000 non-null   Int64  \n",
      " 1   MonthYear              8000 non-null   Int64  \n",
      " 2   EventCode              8000 non-null   object \n",
      " 3   EventBaseCode          8000 non-null   object \n",
      " 4   EventRootCode          8000 non-null   object \n",
      " 5   QuadClass              8000 non-null   Int64  \n",
      " 6   GoldsteinScale         8000 non-null   float64\n",
      " 7   Actor1Code             7201 non-null   object \n",
      " 8   Actor1Name             7201 non-null   object \n",
      " 9   Actor1CountryCode      4866 non-null   object \n",
      " 10  ActionGeo_CountryCode  7758 non-null   object \n",
      " 11  ActionGeo_Lat          7751 non-null   float64\n",
      " 12  ActionGeo_Long         7751 non-null   float64\n",
      " 13  NumArticles            8000 non-null   Int64  \n",
      "dtypes: Int64(4), float64(3), object(7)\n",
      "memory usage: 906.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# check data types\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fabb5",
   "metadata": {},
   "source": [
    "All the values in the columns have an actual meaning here that is hard to\n",
    "approximate using mean/median or mode.\n",
    "I will fill the missing values with a new value making it clear to the model\n",
    "that the value is missing.\n",
    "\n",
    "I will impute the numerical values (such as latitude, longitude and\n",
    "GoldsteinScale) with a value far outside the possible range (e.g., latitude\n",
    "999, longitude 999) \n",
    "I will impute the categorical values (such as Actor1Code, Actor1Name) with a\n",
    "new category for unknown.\n",
    "To accomplish this, I will just fill it with \"UNKNOWN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ef81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['SQLDATE', 'MonthYear', 'QuadClass', 'GoldsteinScale', 'ActionGeo_Lat', 'ActionGeo_Long', 'NumArticles']\n",
      "Categorical columns: ['EventCode', 'EventBaseCode', 'EventRootCode', 'Actor1Code', 'Actor1Name', 'Actor1CountryCode', 'ActionGeo_CountryCode']\n",
      "Missing values after imputation:\n",
      "SQLDATE                  0.0\n",
      "MonthYear                0.0\n",
      "EventCode                0.0\n",
      "EventBaseCode            0.0\n",
      "EventRootCode            0.0\n",
      "QuadClass                0.0\n",
      "GoldsteinScale           0.0\n",
      "Actor1Code               0.0\n",
      "Actor1Name               0.0\n",
      "Actor1CountryCode        0.0\n",
      "ActionGeo_CountryCode    0.0\n",
      "ActionGeo_Lat            0.0\n",
      "ActionGeo_Long           0.0\n",
      "NumArticles              0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>MIL</td>\n",
       "      <td>COMMANDER</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>RS</td>\n",
       "      <td>50.6107</td>\n",
       "      <td>36.5802</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UKRAINIAN</td>\n",
       "      <td>UKR</td>\n",
       "      <td>RS</td>\n",
       "      <td>55.7522</td>\n",
       "      <td>37.6156</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>CVL</td>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>JO</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>UKRGOV</td>\n",
       "      <td>KIEV</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UP</td>\n",
       "      <td>50.4333</td>\n",
       "      <td>30.5167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>SP</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "0  20241107     202411       180           180            18          4   \n",
       "1  20240922     202409       190           190            19          4   \n",
       "2  20241107     202411       180           180            18          4   \n",
       "3  20240922     202409       190           190            19          4   \n",
       "4  20240922     202409       190           190            19          4   \n",
       "\n",
       "   GoldsteinScale Actor1Code Actor1Name Actor1CountryCode  \\\n",
       "0            -9.0        MIL  COMMANDER           UNKNOWN   \n",
       "1           -10.0        UKR  UKRAINIAN               UKR   \n",
       "2            -9.0        CVL  COMMUNITY           UNKNOWN   \n",
       "3           -10.0     UKRGOV       KIEV               UKR   \n",
       "4           -10.0    UNKNOWN    UNKNOWN           UNKNOWN   \n",
       "\n",
       "  ActionGeo_CountryCode  ActionGeo_Lat  ActionGeo_Long  NumArticles  \n",
       "0                    RS        50.6107         36.5802           10  \n",
       "1                    RS        55.7522         37.6156            4  \n",
       "2                    JO        31.0000         36.0000           10  \n",
       "3                    UP        50.4333         30.5167            1  \n",
       "4                    SP        28.0000        -15.5000            4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputation strategy\n",
    "# numerical values: use 999 (far outside normal range)\n",
    "# categorical values: use \"UNKNOWN\"\n",
    "\n",
    "# automatically identify column types\n",
    "numerical_columns = df_train.select_dtypes(\n",
    "    include=['int64', 'float64']\n",
    ").columns.tolist()\n",
    "categorical_columns = df_train.select_dtypes(\n",
    "    include=['object', 'string']\n",
    ").columns.tolist()\n",
    "\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# create imputation strategy dynamically\n",
    "imputation_strategy = {}\n",
    "\n",
    "# add categorical imputation (UNKNOWN for all)\n",
    "for col in categorical_columns:\n",
    "    imputation_strategy[col] = \"UNKNOWN\"\n",
    "\n",
    "# add numerical imputation (999 for all)\n",
    "for col in numerical_columns:\n",
    "    imputation_strategy[col] = 999\n",
    "\n",
    "# fill missing values with strategy\n",
    "df_train.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "# check result\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df_train.isna().mean())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f721f7",
   "metadata": {},
   "source": [
    "Great! Now there are no missing values in the df_train.\n",
    "I hope that this method makes any sense.\n",
    "The only way to find out is to try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6eccd",
   "metadata": {},
   "source": [
    "## Take care of the columns for date\n",
    "\n",
    "There is a column called \"SQLDATE\" which is a date in the format YYYYMMDD.\n",
    "This is not very useful for modeling, so I will convert it to more informative\n",
    "features such as year, month, day of year, day of week, and whether it is a\n",
    "weekend or not.\n",
    "\n",
    "I will also drop the intermediate date column.\n",
    "\n",
    "Beyond this, there is a second column called \"MonthYear\" which seems to contain\n",
    "redundant information.\n",
    "It should probably be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b947918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime first\n",
    "df_train['date'] = pd.to_datetime(df_train['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "# Extract useful components\n",
    "df_train['year'] = df_train['date'].dt.year\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_train['day_of_year'] = df_train['date'].dt.dayofyear  # 1-365\n",
    "df_train['day_of_week'] = df_train['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_train['is_weekend'] = df_train['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Drop the intermediate date column and the original date related columns\n",
    "df_train = df_train.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131b891",
   "metadata": {},
   "source": [
    "## Check if I need to One-Hot-Encode the categorical features\n",
    "\n",
    "Right now, many of the categorical columns use integers to encode the values.\n",
    "While this will probably work, it also introduces an order to the values.\n",
    "A model may learn some patterns from this that don't really exist.\n",
    "\n",
    "However, one-hot-encoding will increase the number of features by a lot.\n",
    "This may be a problem if the number of features is too high.\n",
    "\n",
    "Check which columns should not have an order and\n",
    "if one-hot-encoding is feasible here by having a look at the number of\n",
    "unique values in each column, then decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa3899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventCode                  17\n",
       "EventBaseCode              15\n",
       "EventRootCode              11\n",
       "QuadClass                   4\n",
       "GoldsteinScale             13\n",
       "Actor1Code                488\n",
       "Actor1Name                860\n",
       "Actor1CountryCode         152\n",
       "ActionGeo_CountryCode     172\n",
       "ActionGeo_Lat            1355\n",
       "ActionGeo_Long           1382\n",
       "NumArticles                29\n",
       "year                        1\n",
       "month                      10\n",
       "day_of_year                17\n",
       "day_of_week                 7\n",
       "is_weekend                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed600fe",
   "metadata": {},
   "source": [
    "Dang! Those are a lot of unique values in the categorical columns.\n",
    "The cardinality of these features is way too high for one-hot encoding, as it\n",
    "would blow up the feature space and hurt both memory and model generalization.\n",
    "\n",
    "So, instead, I will use native categorical encoding in the ML algorithms I aim\n",
    "to use: XGBoost, CatBoost, and LightGBM.\n",
    "- XGBoost, CatBoost, and LightGBM can handle categorical features by mapping\n",
    "them to integer codes (label encoding)\n",
    "- CatBoost/LightGBM even use more advanced target encoding under the hood.\n",
    "- Assign each unique category a unique integer, including `\"UNKNOWN\"` for missing\n",
    "values.\n",
    "\n",
    "Here's the plan:\n",
    "I will use the `OrdinalEncoder` from `sklearn` to encode the categorical columns.\n",
    "This is an encoder object that can be fitted on the training set, saved to a\n",
    "file, and then applied to train, test, and any new data, too.\n",
    "This is important as the encoding must be the same for train data and any new\n",
    "data the model is queried on, including the test data.\n",
    "If, on the other hand, the encoding is different, the model will not be able to\n",
    "make meaningful predictions.\n",
    "It also supports handling unknown values.\n",
    "For example, if there are categories in the test data that were not seen in the\n",
    "training data, the encoder will assign them a value of choice.\n",
    "I will use -1 for unknown values to signal the algorithm it's a new category it\n",
    "wasn't trained on.\n",
    "\n",
    "Usually, it would be important to save the encoder to a file.\n",
    "Here, however, I only develop the parts to get a rapid prototype and\n",
    "conceptualize.\n",
    "Once I made everything work, I will refactor and export this to a script.\n",
    "There, I will save the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1827af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>50.6107</td>\n",
       "      <td>36.5802</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>55.7522</td>\n",
       "      <td>37.6156</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>50.4333</td>\n",
       "      <td>30.5167</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0       12.0           11.0            9.0          4            -9.0   \n",
       "1       16.0           14.0           10.0          4           -10.0   \n",
       "2       12.0           11.0            9.0          4            -9.0   \n",
       "3       16.0           14.0           10.0          4           -10.0   \n",
       "4       16.0           14.0           10.0          4           -10.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  ActionGeo_CountryCode  \\\n",
       "0       267.0       156.0              138.0                  129.0   \n",
       "1       423.0       796.0              137.0                  129.0   \n",
       "2        85.0       158.0              138.0                   74.0   \n",
       "3       425.0       385.0              137.0                  155.0   \n",
       "4       429.0       808.0              138.0                  139.0   \n",
       "\n",
       "   ActionGeo_Lat  ActionGeo_Long  NumArticles  year  month  day_of_year  \\\n",
       "0        50.6107         36.5802           10  2024     11          312   \n",
       "1        55.7522         37.6156            4  2024      9          266   \n",
       "2        31.0000         36.0000           10  2024     11          312   \n",
       "3        50.4333         30.5167            1  2024      9          266   \n",
       "4        28.0000        -15.5000            4  2024      9          266   \n",
       "\n",
       "   day_of_week  is_weekend  \n",
       "0            3           0  \n",
       "1            6           1  \n",
       "2            3           0  \n",
       "3            6           1  \n",
       "4            6           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize an encoder for categorical data\n",
    "# encodes categorical data as integers (example \"USA\" may get 1 or whatever)\n",
    "# use -1 for unknown values to signal algorithm it's a new category it wasn't trained on\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit encoder on train set and transform it right away\n",
    "df_train[categorical_columns] = encoder.fit_transform(df_train[categorical_columns])\n",
    "\n",
    "# check the result\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32afb927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.939250</td>\n",
       "      <td>11.494375</td>\n",
       "      <td>8.444000</td>\n",
       "      <td>3.428625</td>\n",
       "      <td>-6.558462</td>\n",
       "      <td>258.119250</td>\n",
       "      <td>486.863625</td>\n",
       "      <td>106.73325</td>\n",
       "      <td>102.44650</td>\n",
       "      <td>63.568798</td>\n",
       "      <td>45.376968</td>\n",
       "      <td>5.376875</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.044125</td>\n",
       "      <td>263.063125</td>\n",
       "      <td>4.554125</td>\n",
       "      <td>0.664625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.777569</td>\n",
       "      <td>3.997151</td>\n",
       "      <td>2.778503</td>\n",
       "      <td>1.155994</td>\n",
       "      <td>6.591001</td>\n",
       "      <td>135.355258</td>\n",
       "      <td>250.720787</td>\n",
       "      <td>39.93612</td>\n",
       "      <td>47.61854</td>\n",
       "      <td>168.623200</td>\n",
       "      <td>181.833621</td>\n",
       "      <td>4.031113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.516564</td>\n",
       "      <td>46.460564</td>\n",
       "      <td>2.200835</td>\n",
       "      <td>0.472151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>-172.178309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>31.416700</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>137.00000</td>\n",
       "      <td>107.00000</td>\n",
       "      <td>33.871900</td>\n",
       "      <td>34.333300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>411.250000</td>\n",
       "      <td>757.250000</td>\n",
       "      <td>138.00000</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>46.961500</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>859.000000</td>\n",
       "      <td>151.00000</td>\n",
       "      <td>171.00000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "count  8000.000000    8000.000000    8000.000000     8000.0     8000.000000   \n",
       "mean     12.939250      11.494375       8.444000   3.428625       -6.558462   \n",
       "std       4.777569       3.997151       2.778503   1.155994        6.591001   \n",
       "min       0.000000       0.000000       0.000000        1.0      -10.000000   \n",
       "25%      12.000000      11.000000       9.000000        4.0      -10.000000   \n",
       "50%      16.000000      14.000000      10.000000        4.0      -10.000000   \n",
       "75%      16.000000      14.000000      10.000000        4.0       -9.000000   \n",
       "max      16.000000      14.000000      10.000000        4.0        9.000000   \n",
       "\n",
       "        Actor1Code   Actor1Name  Actor1CountryCode  ActionGeo_CountryCode  \\\n",
       "count  8000.000000  8000.000000         8000.00000             8000.00000   \n",
       "mean    258.119250   486.863625          106.73325              102.44650   \n",
       "std     135.355258   250.720787           39.93612               47.61854   \n",
       "min       0.000000     0.000000            0.00000                0.00000   \n",
       "25%     134.000000   304.000000           64.00000               67.00000   \n",
       "50%     242.000000   461.000000          137.00000              107.00000   \n",
       "75%     411.250000   757.250000          138.00000              154.00000   \n",
       "max     487.000000   859.000000          151.00000              171.00000   \n",
       "\n",
       "       ActionGeo_Lat  ActionGeo_Long  NumArticles    year        month  \\\n",
       "count    8000.000000     8000.000000       8000.0  8000.0  8000.000000   \n",
       "mean       63.568798       45.376968     5.376875  2024.0     9.044125   \n",
       "std       168.623200      181.833621     4.031113     0.0     1.516564   \n",
       "min       -44.000000     -172.178309          1.0  2024.0     1.000000   \n",
       "25%        31.416700       -2.000000          2.0  2024.0     9.000000   \n",
       "50%        33.871900       34.333300          4.0  2024.0     9.000000   \n",
       "75%        46.961500       38.000000         10.0  2024.0     9.000000   \n",
       "max       999.000000      999.000000         60.0  2024.0    12.000000   \n",
       "\n",
       "       day_of_year  day_of_week   is_weekend  \n",
       "count  8000.000000  8000.000000  8000.000000  \n",
       "mean    263.063125     4.554125     0.664625  \n",
       "std      46.460564     2.200835     0.472151  \n",
       "min       4.000000     0.000000     0.000000  \n",
       "25%     266.000000     3.000000     0.000000  \n",
       "50%     266.000000     6.000000     1.000000  \n",
       "75%     266.000000     6.000000     1.000000  \n",
       "max     350.000000     6.000000     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of these new values\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5042b",
   "metadata": {},
   "source": [
    "Very interesting to see: GoldsteinScale is very skewed.\n",
    "It represents intensity of interactions between actors.\n",
    "Negative values mean conflictual interactions.\n",
    "A -10 is actually an act of war.\n",
    "A positive value means a cooperative action.\n",
    "\n",
    "In this data, there's almost only bad events happening.\n",
    "I don't know if this is due to my hashing in SQL, just random or because most\n",
    "of the news happens to be about bad things.\n",
    "I mean from my own personal experience, it makes sense.\n",
    "A lot of news focuses on bad things.\n",
    "\n",
    "I don't want to go any deeper into interpreting this, but it's noteworthy in\n",
    "my opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5daef94",
   "metadata": {},
   "source": [
    "## No scaling or normalization is needed\n",
    "\n",
    "The range of the features differs a lot.\n",
    "Many algorithms would suffer from this.\n",
    "\n",
    "However, I already decided to use tree-based models only.\n",
    "This is actually for a personal reason.\n",
    "I will have to use these algorithms for a different project in the future, so I\n",
    "already want to gather some experience and get familiar with them.\n",
    "\n",
    "Tree-based models like XGBoost, CatBoost, and LightGBM do not require feature\n",
    "scaling or normalization for either categorical features (integer encoded) or\n",
    "numerical features.\n",
    "\n",
    "These algorithms split data based on feature values and thresholds, not on\n",
    "Euclidean distance, so scaling has no effect on their performance or accuracy.\n",
    "\n",
    "Label-encoded categorical variables are treated as distinct categories,\n",
    "regardless of their actual integer value range.\n",
    "\n",
    "The models can be trained directly with the current integer and numeric features.\n",
    "\n",
    "If I had used different algorithms, I would have to check if scaling or\n",
    "normalization is needed.\n",
    "Here, however, this is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03c60d",
   "metadata": {},
   "source": [
    "## Divide into features and target\n",
    "\n",
    "What's left now is to extract the features and the target.\n",
    "The target is the number of articles in the media `NumArticles`.\n",
    "The features are all the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1d3984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>50.6107</td>\n",
       "      <td>36.5802</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>55.7522</td>\n",
       "      <td>37.6156</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>50.4333</td>\n",
       "      <td>30.5167</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0       12.0           11.0            9.0          4            -9.0   \n",
       "1       16.0           14.0           10.0          4           -10.0   \n",
       "2       12.0           11.0            9.0          4            -9.0   \n",
       "3       16.0           14.0           10.0          4           -10.0   \n",
       "4       16.0           14.0           10.0          4           -10.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  ActionGeo_CountryCode  \\\n",
       "0       267.0       156.0              138.0                  129.0   \n",
       "1       423.0       796.0              137.0                  129.0   \n",
       "2        85.0       158.0              138.0                   74.0   \n",
       "3       425.0       385.0              137.0                  155.0   \n",
       "4       429.0       808.0              138.0                  139.0   \n",
       "\n",
       "   ActionGeo_Lat  ActionGeo_Long  year  month  day_of_year  day_of_week  \\\n",
       "0        50.6107         36.5802  2024     11          312            3   \n",
       "1        55.7522         37.6156  2024      9          266            6   \n",
       "2        31.0000         36.0000  2024     11          312            3   \n",
       "3        50.4333         30.5167  2024      9          266            6   \n",
       "4        28.0000        -15.5000  2024      9          266            6   \n",
       "\n",
       "   is_weekend  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features and check result\n",
    "X_train = df_train.drop(columns=[\"NumArticles\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d6583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1     4\n",
       "2    10\n",
       "3     1\n",
       "4     4\n",
       "Name: NumArticles, dtype: Int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target and check resuls\n",
    "y_train = df_train[\"NumArticles\"]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378f060",
   "metadata": {},
   "source": [
    "Amazing! I'd say everything looks great.\n",
    "This should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b0f59",
   "metadata": {},
   "source": [
    "## Collect the steps and refactor them into a function\n",
    "\n",
    "This exact same logic must be applied to the df_test, too, so the model will be\n",
    "able to make meaningful predictions.\n",
    "\n",
    "I will collect the steps and refactor them into a function.\n",
    "This function can not only be used for the df_test, but it will also be useful\n",
    "for later when I export this notebook as a script.\n",
    "\n",
    "Make sure to use the df_train and then apply whatever it learned to the df_test.\n",
    "Never learn from the full dataset or from the df_test itself.\n",
    "An example for this is checking number of missing values to decide which columns\n",
    "to drop and scaling the data in case it is needed.\n",
    "\n",
    "Make sure to fit encoding (like category codes) on the training set, then apply\n",
    "to the test set to avoid data leakage.\n",
    "\n",
    "Make sure train and test columns are in the same order.\n",
    "\n",
    "Save the data to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446b02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for saving the labels\n",
    "def save_series_as_parquet(series, filepath):\n",
    "    \"\"\"Save a pandas Series as parquet file\"\"\"\n",
    "    # Convert Series to DataFrame with proper column name\n",
    "    df = series.to_frame(name=series.name if series.name else 'target')\n",
    "    df.to_parquet(filepath)\n",
    "\n",
    "# function for data preparation\n",
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    is_train: bool,\n",
    "    encoder: Optional[OrdinalEncoder] = None,\n",
    "    encoder_path: Optional[str] = None,\n",
    "    save_data: bool = False,\n",
    "    save_path_dir: Optional[str] = None,\n",
    "    path_repo: Optional[str] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training or testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constants\n",
    "    \n",
    "    # target value or rather label\n",
    "    target_label = \"NumArticles\"\n",
    "    \n",
    "    # path to intermediate data\n",
    "    if save_data == True:\n",
    "        PATH_DATA = Path(path_repo) / \"data/intermediate\"\n",
    "\n",
    "    # Handle missing values\n",
    "\n",
    "    # check for missing values and extract columns with >= 50% missing\n",
    "    missing_rates = df.isnull().mean()\n",
    "    columns_high_missing = missing_rates[missing_rates >= 0.5].index.tolist()\n",
    "\n",
    "    # drop columns with 50% or more missing\n",
    "    df = df.drop(columns=columns_high_missing)\n",
    "\n",
    "    # automatically identify column types\n",
    "    numerical_columns = df.select_dtypes(\n",
    "        include=['int64', 'float64']\n",
    "    ).columns.tolist()\n",
    "    categorical_columns = df.select_dtypes(\n",
    "        include=['object', 'string']\n",
    "    ).columns.tolist()\n",
    "    \n",
    "    # create imputation strategy dynamically\n",
    "    # numerical values: use 999 (far outside normal range)\n",
    "    # categorical values: use \"UNKNOWN\"\n",
    "    imputation_strategy = {}\n",
    "\n",
    "    # add categorical imputation (UNKNOWN for all)\n",
    "    for col in categorical_columns:\n",
    "        imputation_strategy[col] = \"UNKNOWN\"\n",
    "\n",
    "    # add numerical imputation (999 for all)\n",
    "    for col in numerical_columns:\n",
    "        imputation_strategy[col] = 999\n",
    "\n",
    "    # fill missing values with strategy\n",
    "    df.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "    # Handle time and data columns\n",
    "    # convert column \"SQLDATE\" to more meaningful date and time info\n",
    "    # this will allos models to learn from it better\n",
    "\n",
    "    # convert to datetime first\n",
    "    df['date'] = pd.to_datetime(df['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "    # extract useful components\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear  # 1-365\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # drop the intermediate date column and the original date related columns\n",
    "    df = df.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)\n",
    "\n",
    "\n",
    "    # Handle categorical data by numerical encoding\n",
    "    \n",
    "    # if train data is passed, fit_transform and save encoder\n",
    "    if is_train == True:\n",
    "        \n",
    "        # initialize an encoder for categorical data\n",
    "        # encodes categorical data as integers\n",
    "        # example \"USA\" may get 1 or whatever\n",
    "        # use -1 for unknown values\n",
    "        # this signals algorithm it's a new category it wasn't trained on\n",
    "        encoder = OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        )\n",
    "        \n",
    "        # fit encoder on train set and transform data it right away\n",
    "        df[categorical_columns] = encoder.fit_transform(df[categorical_columns])\n",
    "        \n",
    "        # if data is supposed to be saved, save encoder to file\n",
    "        if save_data == True:\n",
    "            encoder_path = 'ordinal_encoder_prototype.pkl' \n",
    "            joblib.dump(encoder, encoder_path)\n",
    "\n",
    "            # log as part of a custom model (for later use with ML model)\n",
    "            with mlflow.start_run():\n",
    "                # log just the encoder as artifact for now\n",
    "                mlflow.log_artifact(encoder_path, artifact_path='preprocessing')\n",
    "\n",
    "                # clean up local file after logging\n",
    "                # so it's in just one location: artifact store\n",
    "                os.remove(encoder_path)\n",
    "\n",
    "\n",
    "    # if test data is passed, load the encoder and transform test data\n",
    "    elif is_train == False:\n",
    "        \n",
    "        # we need the run_id to locate the encoder in the artifact store\n",
    "        if encoder is None and encoder_path is None:\n",
    "            raise ValueError(\"For test data, either 'encoder' object or 'encoder_path' (run_id) must be provided\")\n",
    "        \n",
    "        # if encoder object is passed directly, use it\n",
    "        if encoder is not None:\n",
    "            loaded_encoder = encoder\n",
    "        \n",
    "        # if encoder_path (run_id) is provided, load from artifact store\n",
    "        elif encoder_path is not None:\n",
    "            # download the encoder from MLflow artifact store\n",
    "            # encoder_path should be the run_id where the encoder was logged\n",
    "            artifact_path = mlflow.artifacts.download_artifacts(\n",
    "                f\"runs:/{encoder_path}/preprocessing/ordinal_encoder_prototype.pkl\"\n",
    "            )\n",
    "            # load the encoder from the downloaded file\n",
    "            loaded_encoder = joblib.load(artifact_path)\n",
    "            \n",
    "            # clean up: delete the temporary downloaded file\n",
    "            os.remove(artifact_path)\n",
    "        \n",
    "        # apply the loaded encoder to transform test data (only transform, no fitting)\n",
    "        df[categorical_columns] = loaded_encoder.transform(df[categorical_columns])\n",
    "\n",
    "\n",
    "    # Extract features and labels\n",
    "    # get features\n",
    "    X = df.drop(columns=[target_label])\n",
    "\n",
    "    # get target\n",
    "    y = df[target_label]\n",
    "    \n",
    "    \n",
    "    # Save data to parquet files if desired\n",
    "    if save_data == True:\n",
    "        \n",
    "        # ensure the intermediate data directory exists\n",
    "        PATH_DATA.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # if path to directory to save data to was passed, use it\n",
    "        if save_path_dir is not None:\n",
    "            save_name = PATH_DATA / save_path_dir\n",
    "        # if not passed, use a default path\n",
    "        else:\n",
    "            # count number of directories in intermediate data dir\n",
    "            num_dirs = sum(1 for p in PATH_DATA.iterdir() if p.is_dir())\n",
    "            save_name = PATH_DATA / f\"gdelt_events_2024_subset_version_{num_dirs}\"\n",
    "            \n",
    "        # ensure the save directory exists\n",
    "        save_name.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # switch between train and test features and labels\n",
    "        if is_train == True:\n",
    "            X_name = \"X_train\"\n",
    "            y_name = \"y_train\"\n",
    "        else:\n",
    "            X_name = \"X_test\"\n",
    "            y_name = \"y_test\"\n",
    "            \n",
    "        # save data to parquet files\n",
    "        X.to_parquet(save_name / f\"{X_name}.parquet\")\n",
    "        save_series_as_parquet(y, save_name / f\"{y_name}.parquet\")\n",
    "\n",
    "    # always return features and labels\n",
    "    # return encoder if train was used\n",
    "    if is_train == True:\n",
    "        return X, y, encoder\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "425c8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of previously processed train data to compare if output is same\n",
    "df_train_backup = df_train.copy()\n",
    "X_train_backup = X_train.copy()\n",
    "y_train_backup = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4833d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# briefly check if backup worked\n",
    "print(df_train_backup.equals(df_train))\n",
    "print(X_train_backup.equals(X_train))\n",
    "print(y_train_backup.equals(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa803da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data again fresh from file, because it was already processed\n",
    "df_train = pd.read_parquet(PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1558459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = df_train,\n",
    "    is_train = True,\n",
    "    save_data = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d502b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names comparison:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "\n",
      "Value comparison:\n",
      "X values equal: True\n",
      "y values equal: True\n",
      "\n",
      "Index comparison:\n",
      "[ True  True  True ...  True  True  True]\n",
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# compare column names\n",
    "print(\"Column names comparison:\")\n",
    "print(X_train_backup.columns == X_train_new.columns)\n",
    "\n",
    "\n",
    "# compare values element by element (ignoring index/column names)\n",
    "print(\"\\nValue comparison:\")\n",
    "print(f\"X values equal: {X_train_new.values.shape == X_train_backup.values.shape and (X_train_new.values == X_train_backup.values).all()}\")\n",
    "print(f\"y values equal: {y_train_new.values.shape == y_train_backup.values.shape and (y_train_new.values == y_train_backup.values).all()}\")\n",
    "\n",
    "# compare index now\n",
    "print(\"\\nIndex comparison:\")\n",
    "print(X_train_new.index == X_train_backup.index)\n",
    "print(y_train_new.index == y_train_backup.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fae3d8",
   "metadata": {},
   "source": [
    "Great! The data in there is the same.\n",
    "All column names match and the values are the same, too for both features (X)\n",
    "and the labels (y).\n",
    "Even the index is the same. I actually didn't expect that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2d46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for test data\n",
    "# pass the new encoder here\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = df_test,\n",
    "    is_train = False,\n",
    "    save_data = False,\n",
    "    encoder = encoder_new\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2784b",
   "metadata": {},
   "source": [
    "I'll now also check this function for the test data.\n",
    "It's bad to look at test data, but I guess verifying the code works by\n",
    "comparing columns and printing the head is acceptable.\n",
    "Without it, I wouldn't even know if my function works.\n",
    "\n",
    "In theory, I could also just run it in `is_train = False` mode for the train\n",
    "data, but I want to be completely sure.\n",
    "\n",
    "Honestly, this cannot be seen as data leakage, because I will obtain like zero\n",
    "information from looking at these numbers.\n",
    "To make this even more clear, I'll just print the first row.\n",
    "This is just enough for me to see the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4d9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing columns:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>37.2879</td>\n",
       "      <td>-1.74901</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0        4.0            4.0            3.0          1             8.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  ActionGeo_CountryCode  \\\n",
       "0       134.0       272.0              138.0                  139.0   \n",
       "\n",
       "   ActionGeo_Lat  ActionGeo_Long  year  month  day_of_year  day_of_week  \\\n",
       "0        37.2879        -1.74901  2024      7          190            0   \n",
       "\n",
       "   is_weekend  \n",
       "0           0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare columns to backup -> columns must match\n",
    "print(\"Comparing columns:\")\n",
    "print(X_test_new.columns == X_train_backup.columns)\n",
    "\n",
    "# print only first row to get some feedback if function works\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9954d94",
   "metadata": {},
   "source": [
    "Amazing! This can be used!\n",
    "\n",
    "But I need to test the writing function.\n",
    "This will also log to MLFLow, so there are many more break points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d96c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dapper-pig-414 at: http://127.0.0.1:5001/#/experiments/4/runs/60b44e726c544a4c93629428dbdd6dd8\n",
      "🧪 View experiment at: http://127.0.0.1:5001/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = df_train,\n",
    "    is_train = True,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b684d",
   "metadata": {},
   "source": [
    "Great! This works!\n",
    "The data is saved and the encoder is logged to MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c3cd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ed2c904ee740c8a9f391f8040cd74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the function for test data\n",
    "# pass run ID as encoder path\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = df_test,\n",
    "    is_train = False,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO,\n",
    "    encoder_path = \"60b44e726c544a4c93629428dbdd6dd8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c8ea504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>37.2879</td>\n",
       "      <td>-1.74901</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0        4.0            4.0            3.0          1             8.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  ActionGeo_CountryCode  \\\n",
       "0       134.0       272.0              138.0                  139.0   \n",
       "\n",
       "   ActionGeo_Lat  ActionGeo_Long  year  month  day_of_year  day_of_week  \\\n",
       "0        37.2879        -1.74901  2024      7          190            0   \n",
       "\n",
       "   is_weekend  \n",
       "0           0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to first row of previous run\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771bf2e",
   "metadata": {},
   "source": [
    "Amazing! This works, too! So, this is my data prep and I can go on I think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c68ee",
   "metadata": {},
   "source": [
    "## Get a 1000 Samples Subset from Processed Train Data\n",
    "\n",
    "10k rows is already not that much data for ML, but it can still run for some\n",
    "time.\n",
    "For rapid prototyping in interactive Jupyter notebooks, I will get an even\n",
    "smaller subset of just 1k rows.\n",
    "\n",
    "I will draw it directly from the processed train data, and use it when I\n",
    "develop in interactive mode.\n",
    "I can then run a script using the full data in background later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "192aad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 1000 random samples\n",
    "df_train_subset1k = df_train.sample(n=1000, random_state=42)\n",
    "\n",
    "# check it out\n",
    "df_train_subset1k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc54cd",
   "metadata": {},
   "source": [
    "I won't save this subset right here, because I will extract the logic to a\n",
    "script now anyway and do it there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
