{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b470433c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "In this notebook, I have a look at the data I downloaded from BigQuery.\n",
    "I already split the data into train and test sets right away in the script for\n",
    "downloading the data to prevent a data leakage.\n",
    "\n",
    "Here, I will inspect the train split and see what needs to be done to prepare\n",
    "it for modeling.\n",
    "I will perform the scripts, then collect them in a function and apply it to the\n",
    "test split, too.\n",
    "Whatever decisions need to be made will be based on the train split exclusively.\n",
    "Nothing will be decided based on the test split.\n",
    "In case dataset wide statistics are needed for some transformation, they will\n",
    "be based on the train split exclusively, too, and later applied to the test\n",
    "split.\n",
    "\n",
    "The workflow from this note will be exported to the script\n",
    "`scripts/prepare_data_for_modeling.py`.\n",
    "\n",
    "## Environment\n",
    "\n",
    "To use this project's uv environment, make sure you installed it according to\n",
    "the instructions in the README.md file.\n",
    "\n",
    "Then, connect to the `.venv` kernel.\n",
    "Check the path to the kernel to make sure it's the right one.\n",
    "It should be `.venv/bin/python`.\n",
    "\n",
    "Run the next cell to check if you use the correct kernel.\n",
    "It should output this:\n",
    "\n",
    "```\n",
    "<path_to_wherever_you_cloned_the_repo_to>/gdelt-newsimpact/.venv/bin/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f6eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fakrueg/projects/courses/datatalks/mlops-zoomcamp/mlopsproject2/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9268f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f324b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import joblib\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "PATH_REPO = Path(\".\").resolve().parent\n",
    "PATH_DATA = PATH_REPO / \"data\" / \"raw\"\n",
    "PATH_TRAIN = PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\"\n",
    "PATH_TEST = PATH_DATA / \"gdelt_events_2024_subset_10k_test.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec1866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1755362327633, experiment_id='1', last_update_time=1755362327633, lifecycle_stage='active', name='testing_setup', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for saving any feature scalers or encoders to the artifact store\n",
    "\n",
    "# set MLFlow tracking URI or rather: basically connect to the MLFlow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# set experiment\n",
    "mlflow.set_experiment(\"testing_setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfafa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>...</th>\n",
       "      <th>Actor2CountryCode</th>\n",
       "      <th>Actor2Type1Code</th>\n",
       "      <th>Actor2Type2Code</th>\n",
       "      <th>Actor2Type3Code</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>IRNGOV</td>\n",
       "      <td>IRANIAN</td>\n",
       "      <td>IRN</td>\n",
       "      <td>...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR16</td>\n",
       "      <td>35.7131</td>\n",
       "      <td>47.2656</td>\n",
       "      <td>-3071164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>ISRMIL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISR</td>\n",
       "      <td>...</td>\n",
       "      <td>LBN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS00</td>\n",
       "      <td>31.4167</td>\n",
       "      <td>34.3333</td>\n",
       "      <td>-797156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UKRAINIAN</td>\n",
       "      <td>UKR</td>\n",
       "      <td>...</td>\n",
       "      <td>RUS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RS</td>\n",
       "      <td>RS46</td>\n",
       "      <td>54.7680</td>\n",
       "      <td>45.8370</td>\n",
       "      <td>-2985097</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>ISRMED</td>\n",
       "      <td>ISRAELI</td>\n",
       "      <td>ISR</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>MIL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS03</td>\n",
       "      <td>32.9000</td>\n",
       "      <td>35.3333</td>\n",
       "      <td>-779978</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>GOV</td>\n",
       "      <td>PRIME MINISTER</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>USDE</td>\n",
       "      <td>39.3498</td>\n",
       "      <td>-75.5148</td>\n",
       "      <td>DE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "0  20241107     202411       180           180            18          4   \n",
       "1  20240922     202409       190           190            19          4   \n",
       "2  20241107     202411       180           180            18          4   \n",
       "3  20240922     202409       190           190            19          4   \n",
       "4  20240922     202409       190           190            19          4   \n",
       "\n",
       "   GoldsteinScale Actor1Code      Actor1Name Actor1CountryCode  ...  \\\n",
       "0            -9.0     IRNGOV         IRANIAN               IRN  ...   \n",
       "1           -10.0     ISRMIL          ISRAEL               ISR  ...   \n",
       "2            -9.0        UKR       UKRAINIAN               UKR  ...   \n",
       "3           -10.0     ISRMED         ISRAELI               ISR  ...   \n",
       "4           -10.0        GOV  PRIME MINISTER              None  ...   \n",
       "\n",
       "  Actor2CountryCode Actor2Type1Code Actor2Type2Code Actor2Type3Code  \\\n",
       "0               AFG            None            None            None   \n",
       "1               LBN            None            None            None   \n",
       "2               RUS            None            None            None   \n",
       "3              None             MIL            None            None   \n",
       "4              None            None            None            None   \n",
       "\n",
       "  ActionGeo_CountryCode ActionGeo_ADM1Code ActionGeo_Lat ActionGeo_Long  \\\n",
       "0                    IR               IR16       35.7131        47.2656   \n",
       "1                    IS               IS00       31.4167        34.3333   \n",
       "2                    RS               RS46       54.7680        45.8370   \n",
       "3                    IS               IS03       32.9000        35.3333   \n",
       "4                    US               USDE       39.3498       -75.5148   \n",
       "\n",
       "  ActionGeo_FeatureID NumArticles  \n",
       "0            -3071164           2  \n",
       "1             -797156           2  \n",
       "2            -2985097          10  \n",
       "3             -779978          10  \n",
       "4                  DE           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from parquet files\n",
    "\n",
    "# train data\n",
    "df_train = pd.read_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\"\n",
    ")\n",
    "\n",
    "# test data\n",
    "df_test = pd.read_parquet(\n",
    "    PATH_DATA / \"gdelt_events_2024_subset_10k_test.parquet\"\n",
    ")\n",
    "\n",
    "# have a look at the train data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6ab11",
   "metadata": {},
   "source": [
    "## Check for Missing Values\n",
    "\n",
    "If there is any column that has a lot of missing values, I will drop it.\n",
    "Columns with just a low percentages may be imputed if there is a meaningful\n",
    "way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6091f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value rates:\n",
      "SQLDATE                  0.000000\n",
      "MonthYear                0.000000\n",
      "EventCode                0.000000\n",
      "EventBaseCode            0.000000\n",
      "EventRootCode            0.000000\n",
      "QuadClass                0.000000\n",
      "GoldsteinScale           0.000000\n",
      "Actor1Code               0.101250\n",
      "Actor1Name               0.101250\n",
      "Actor1CountryCode        0.392750\n",
      "Actor1Type1Code          0.595250\n",
      "Actor1Type2Code          0.977625\n",
      "Actor1Type3Code          1.000000\n",
      "Actor2Code               0.252875\n",
      "Actor2Name               0.252875\n",
      "Actor2CountryCode        0.495125\n",
      "Actor2Type1Code          0.673375\n",
      "Actor2Type2Code          0.978000\n",
      "Actor2Type3Code          0.999500\n",
      "ActionGeo_CountryCode    0.029250\n",
      "ActionGeo_ADM1Code       0.029250\n",
      "ActionGeo_Lat            0.030000\n",
      "ActionGeo_Long           0.030000\n",
      "ActionGeo_FeatureID      0.029250\n",
      "NumArticles              0.000000\n",
      "dtype: float64\n",
      "\n",
      "Columns with >= 50% missing values:\n",
      "['Actor1Type1Code', 'Actor1Type2Code', 'Actor1Type3Code', 'Actor2Type1Code', 'Actor2Type2Code', 'Actor2Type3Code']\n"
     ]
    }
   ],
   "source": [
    "# check for missing values and extract columns with >= 50% missing\n",
    "missing_rates = df_train.isnull().mean()\n",
    "columns_high_missing = missing_rates[missing_rates >= 0.5].index.tolist()\n",
    "\n",
    "print(\"Missing value rates:\")\n",
    "print(missing_rates)\n",
    "print(f\"\\nColumns with >= 50% missing values:\")\n",
    "print(columns_high_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794cb00",
   "metadata": {},
   "source": [
    "For most machine learning projects, it’s reasonable to drop columns with more \n",
    "than 50% missing values, especially if there are plenty of other features.\n",
    "High missingness usually means the feature will be hard to impute reliably and\n",
    "won’t add robust predictive power.\n",
    "\n",
    "One option for imputation would be to use the mode or rather the most frequent\n",
    "value.\n",
    "However, this is data from global events.\n",
    "Imputation is always basically making up data and hoping it's a good guess.\n",
    "Often, for numerical data, a mean or median is a good guess.\n",
    "However, I am afraid in this case, it may not make much sense for some of the\n",
    "columns.\n",
    "For example, if the most frequent value is \"USA\", this will be filled in for\n",
    "all rows where the value is missing.\n",
    "But perhaps there may be a good reason why the value is missing.\n",
    "For example, if the value is missing, it may mean that the event is not\n",
    "related to a country.\n",
    "Because of this, I will treat the missing values as missing by introducing a\n",
    "new category for unknown.\n",
    "I will have to check how they encode this in general and which value can be\n",
    "used for this.\n",
    "Perhaps 0 is a good value for this in case it is not taken for anything else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9446a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns that will be dropped:\n",
      "Actor1Type1Code\n",
      "Actor1Type2Code\n",
      "Actor1Type3Code\n",
      "Actor2Type1Code\n",
      "Actor2Type2Code\n",
      "Actor2Type3Code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SQLDATE                  0.000000\n",
       "MonthYear                0.000000\n",
       "EventCode                0.000000\n",
       "EventBaseCode            0.000000\n",
       "EventRootCode            0.000000\n",
       "QuadClass                0.000000\n",
       "GoldsteinScale           0.000000\n",
       "Actor1Code               0.101250\n",
       "Actor1Name               0.101250\n",
       "Actor1CountryCode        0.392750\n",
       "Actor2Code               0.252875\n",
       "Actor2Name               0.252875\n",
       "Actor2CountryCode        0.495125\n",
       "ActionGeo_CountryCode    0.029250\n",
       "ActionGeo_ADM1Code       0.029250\n",
       "ActionGeo_Lat            0.030000\n",
       "ActionGeo_Long           0.030000\n",
       "ActionGeo_FeatureID      0.029250\n",
       "NumArticles              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print columns that will be dropped\n",
    "print(\"Columns that will be dropped:\")\n",
    "for column in columns_high_missing:\n",
    "    print(column)\n",
    "\n",
    "# drop columns with 50% or more missing values\n",
    "df_train = df_train.drop(columns=columns_high_missing)\n",
    "\n",
    "# check for missing values again get an updated overview\n",
    "df_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03c2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   SQLDATE                8000 non-null   Int64  \n",
      " 1   MonthYear              8000 non-null   Int64  \n",
      " 2   EventCode              8000 non-null   object \n",
      " 3   EventBaseCode          8000 non-null   object \n",
      " 4   EventRootCode          8000 non-null   object \n",
      " 5   QuadClass              8000 non-null   Int64  \n",
      " 6   GoldsteinScale         8000 non-null   float64\n",
      " 7   Actor1Code             7190 non-null   object \n",
      " 8   Actor1Name             7190 non-null   object \n",
      " 9   Actor1CountryCode      4858 non-null   object \n",
      " 10  Actor2Code             5977 non-null   object \n",
      " 11  Actor2Name             5977 non-null   object \n",
      " 12  Actor2CountryCode      4039 non-null   object \n",
      " 13  ActionGeo_CountryCode  7766 non-null   object \n",
      " 14  ActionGeo_ADM1Code     7766 non-null   object \n",
      " 15  ActionGeo_Lat          7760 non-null   float64\n",
      " 16  ActionGeo_Long         7760 non-null   float64\n",
      " 17  ActionGeo_FeatureID    7766 non-null   object \n",
      " 18  NumArticles            8000 non-null   Int64  \n",
      "dtypes: Int64(4), float64(3), object(12)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# check data types\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fabb5",
   "metadata": {},
   "source": [
    "All the values in the columns have an actual meaning here that is hard to\n",
    "approximate using mean/median or mode.\n",
    "I will fill the missing values with a new value making it clear to the model\n",
    "that the value is missing.\n",
    "\n",
    "I will impute the numerical values (such as latitude, longitude and\n",
    "GoldsteinScale) with a value far outside the possible range (e.g., latitude\n",
    "999, longitude 999) \n",
    "I will impute the categorical values (such as Actor1Type1Code, Actor1Type2Code,\n",
    "Actor1Type3Code, Actor2Type1Code, Actor2Type2Code, Actor2Type3Code) with a\n",
    "new category for unknown.\n",
    "To accomplish this, I will just fill it with \"UNKNOWN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ef81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['SQLDATE', 'MonthYear', 'QuadClass', 'GoldsteinScale', 'ActionGeo_Lat', 'ActionGeo_Long', 'NumArticles']\n",
      "Categorical columns: ['EventCode', 'EventBaseCode', 'EventRootCode', 'Actor1Code', 'Actor1Name', 'Actor1CountryCode', 'Actor2Code', 'Actor2Name', 'Actor2CountryCode', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code', 'ActionGeo_FeatureID']\n",
      "Missing values after imputation:\n",
      "SQLDATE                  0.0\n",
      "MonthYear                0.0\n",
      "EventCode                0.0\n",
      "EventBaseCode            0.0\n",
      "EventRootCode            0.0\n",
      "QuadClass                0.0\n",
      "GoldsteinScale           0.0\n",
      "Actor1Code               0.0\n",
      "Actor1Name               0.0\n",
      "Actor1CountryCode        0.0\n",
      "Actor2Code               0.0\n",
      "Actor2Name               0.0\n",
      "Actor2CountryCode        0.0\n",
      "ActionGeo_CountryCode    0.0\n",
      "ActionGeo_ADM1Code       0.0\n",
      "ActionGeo_Lat            0.0\n",
      "ActionGeo_Long           0.0\n",
      "ActionGeo_FeatureID      0.0\n",
      "NumArticles              0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>Actor2CountryCode</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>IRNGOV</td>\n",
       "      <td>IRANIAN</td>\n",
       "      <td>IRN</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFGHAN</td>\n",
       "      <td>AFG</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR16</td>\n",
       "      <td>35.7131</td>\n",
       "      <td>47.2656</td>\n",
       "      <td>-3071164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>ISRMIL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISR</td>\n",
       "      <td>LBN</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>LBN</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS00</td>\n",
       "      <td>31.4167</td>\n",
       "      <td>34.3333</td>\n",
       "      <td>-797156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241107</td>\n",
       "      <td>202411</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>UKRAINIAN</td>\n",
       "      <td>UKR</td>\n",
       "      <td>RUS</td>\n",
       "      <td>RUSSIAN</td>\n",
       "      <td>RUS</td>\n",
       "      <td>RS</td>\n",
       "      <td>RS46</td>\n",
       "      <td>54.7680</td>\n",
       "      <td>45.8370</td>\n",
       "      <td>-2985097</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>ISRMED</td>\n",
       "      <td>ISRAELI</td>\n",
       "      <td>ISR</td>\n",
       "      <td>MIL</td>\n",
       "      <td>MILITARY</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>IS</td>\n",
       "      <td>IS03</td>\n",
       "      <td>32.9000</td>\n",
       "      <td>35.3333</td>\n",
       "      <td>-779978</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240922</td>\n",
       "      <td>202409</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>GOV</td>\n",
       "      <td>PRIME MINISTER</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>US</td>\n",
       "      <td>USDE</td>\n",
       "      <td>39.3498</td>\n",
       "      <td>-75.5148</td>\n",
       "      <td>DE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SQLDATE  MonthYear EventCode EventBaseCode EventRootCode  QuadClass  \\\n",
       "0  20241107     202411       180           180            18          4   \n",
       "1  20240922     202409       190           190            19          4   \n",
       "2  20241107     202411       180           180            18          4   \n",
       "3  20240922     202409       190           190            19          4   \n",
       "4  20240922     202409       190           190            19          4   \n",
       "\n",
       "   GoldsteinScale Actor1Code      Actor1Name Actor1CountryCode Actor2Code  \\\n",
       "0            -9.0     IRNGOV         IRANIAN               IRN        AFG   \n",
       "1           -10.0     ISRMIL          ISRAEL               ISR        LBN   \n",
       "2            -9.0        UKR       UKRAINIAN               UKR        RUS   \n",
       "3           -10.0     ISRMED         ISRAELI               ISR        MIL   \n",
       "4           -10.0        GOV  PRIME MINISTER           UNKNOWN    UNKNOWN   \n",
       "\n",
       "  Actor2Name Actor2CountryCode ActionGeo_CountryCode ActionGeo_ADM1Code  \\\n",
       "0     AFGHAN               AFG                    IR               IR16   \n",
       "1    LEBANON               LBN                    IS               IS00   \n",
       "2    RUSSIAN               RUS                    RS               RS46   \n",
       "3   MILITARY           UNKNOWN                    IS               IS03   \n",
       "4    UNKNOWN           UNKNOWN                    US               USDE   \n",
       "\n",
       "   ActionGeo_Lat  ActionGeo_Long ActionGeo_FeatureID  NumArticles  \n",
       "0        35.7131         47.2656            -3071164            2  \n",
       "1        31.4167         34.3333             -797156            2  \n",
       "2        54.7680         45.8370            -2985097           10  \n",
       "3        32.9000         35.3333             -779978           10  \n",
       "4        39.3498        -75.5148                  DE            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputation strategy\n",
    "# numerical values: use 999 (far outside normal range)\n",
    "# categorical values: use \"UNKNOWN\"\n",
    "\n",
    "# automatically identify column types\n",
    "numerical_columns = df_train.select_dtypes(\n",
    "    include=['int64', 'float64']\n",
    ").columns.tolist()\n",
    "categorical_columns = df_train.select_dtypes(\n",
    "    include=['object', 'string']\n",
    ").columns.tolist()\n",
    "\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# create imputation strategy dynamically\n",
    "imputation_strategy = {}\n",
    "\n",
    "# add categorical imputation (UNKNOWN for all)\n",
    "for col in categorical_columns:\n",
    "    imputation_strategy[col] = \"UNKNOWN\"\n",
    "\n",
    "# add numerical imputation (999 for all)\n",
    "for col in numerical_columns:\n",
    "    imputation_strategy[col] = 999\n",
    "\n",
    "# fill missing values with strategy\n",
    "df_train.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "# check result\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df_train.isna().mean())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f721f7",
   "metadata": {},
   "source": [
    "Great! Now there are no missing values in the df_train.\n",
    "I hope that this method makes any sense.\n",
    "The only way to find out is to try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6eccd",
   "metadata": {},
   "source": [
    "## Take care of the columns for date\n",
    "\n",
    "There is a column called \"SQLDATE\" which is a date in the format YYYYMMDD.\n",
    "This is not very useful for modeling, so I will convert it to more informative\n",
    "features such as year, month, day of year, day of week, and whether it is a\n",
    "weekend or not.\n",
    "\n",
    "I will also drop the intermediate date column.\n",
    "\n",
    "Beyond this, there is a second column called \"MonthYear\" which seems to contain\n",
    "redundant information.\n",
    "It should probably be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b947918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime first\n",
    "df_train['date'] = pd.to_datetime(df_train['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "# Extract useful components\n",
    "df_train['year'] = df_train['date'].dt.year\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_train['day_of_year'] = df_train['date'].dt.dayofyear  # 1-365\n",
    "df_train['day_of_week'] = df_train['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_train['is_weekend'] = df_train['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Drop the intermediate date column and the original date related columns\n",
    "df_train = df_train.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131b891",
   "metadata": {},
   "source": [
    "## Check if I need to One-Hot-Encode the categorical features\n",
    "\n",
    "Right now, many of the categorical columns use integers to encode the values.\n",
    "While this will probably work, it also introduces an order to the values.\n",
    "A model may learn some patterns from this that don't really exist.\n",
    "\n",
    "However, one-hot-encoding will increase the number of features by a lot.\n",
    "This may be a problem if the number of features is too high.\n",
    "\n",
    "Check which columns should not have an order and\n",
    "if one-hot-encoding is feasible here by having a look at the number of\n",
    "unique values in each column, then decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa3899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventCode                  17\n",
       "EventBaseCode              11\n",
       "EventRootCode               8\n",
       "QuadClass                   4\n",
       "GoldsteinScale             10\n",
       "Actor1Code                478\n",
       "Actor1Name                848\n",
       "Actor1CountryCode         147\n",
       "Actor2Code                443\n",
       "Actor2Name                751\n",
       "Actor2CountryCode         149\n",
       "ActionGeo_CountryCode     166\n",
       "ActionGeo_ADM1Code        778\n",
       "ActionGeo_Lat            1310\n",
       "ActionGeo_Long           1339\n",
       "ActionGeo_FeatureID      1403\n",
       "NumArticles                31\n",
       "year                        1\n",
       "month                       9\n",
       "day_of_year                11\n",
       "day_of_week                 6\n",
       "is_weekend                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed600fe",
   "metadata": {},
   "source": [
    "Dang! Those are a lot of unique values in the categorical columns.\n",
    "The cardinality of these features is way too high for one-hot encoding, as it\n",
    "would blow up the feature space and hurt both memory and model generalization.\n",
    "\n",
    "So, instead, I will use native categorical encoding in the ML algorithms I aim\n",
    "to use: XGBoost, CatBoost, and LightGBM.\n",
    "- XGBoost, CatBoost, and LightGBM can handle categorical features by mapping\n",
    "them to integer codes (label encoding)\n",
    "- CatBoost/LightGBM even use more advanced target encoding under the hood.\n",
    "- Assign each unique category a unique integer, including `\"UNKNOWN\"` for missing\n",
    "values.\n",
    "\n",
    "Here's the plan:\n",
    "I will use the `OrdinalEncoder` from `sklearn` to encode the categorical columns.\n",
    "This is an encoder object that can be fitted on the training set, saved to a\n",
    "file, and then applied to train, test, and any new data, too.\n",
    "This is important as the encoding must be the same for train data and any new\n",
    "data the model is queried on, including the test data.\n",
    "If, on the other hand, the encoding is different, the model will not be able to\n",
    "make meaningful predictions.\n",
    "It also supports handling unknown values.\n",
    "For example, if there are categories in the test data that were not seen in the\n",
    "training data, the encoder will assign them a value of choice.\n",
    "I will use -1 for unknown values to signal the algorithm it's a new category it\n",
    "wasn't trained on.\n",
    "\n",
    "Usually, it would be important to save the encoder to a file.\n",
    "Here, however, I only develop the parts to get a rapid prototype and\n",
    "conceptualize.\n",
    "Once I made everything work, I will refactor and export this to a script.\n",
    "There, I will save the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1827af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>...</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>261.0</td>\n",
       "      <td>35.7131</td>\n",
       "      <td>47.2656</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>31.4167</td>\n",
       "      <td>34.3333</td>\n",
       "      <td>777.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>529.0</td>\n",
       "      <td>54.7680</td>\n",
       "      <td>45.8370</td>\n",
       "      <td>543.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>32.9000</td>\n",
       "      <td>35.3333</td>\n",
       "      <td>727.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>...</td>\n",
       "      <td>703.0</td>\n",
       "      <td>39.3498</td>\n",
       "      <td>-75.5148</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0       11.0            7.0            6.0          4            -9.0   \n",
       "1       16.0           10.0            7.0          4           -10.0   \n",
       "2       11.0            7.0            6.0          4            -9.0   \n",
       "3       16.0           10.0            7.0          4           -10.0   \n",
       "4       16.0           10.0            7.0          4           -10.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  Actor2Code  Actor2Name  ...  \\\n",
       "0       187.0       330.0               61.0         0.0        14.0  ...   \n",
       "1       203.0       339.0               64.0       209.0       381.0  ...   \n",
       "2       416.0       792.0              133.0       328.0       584.0  ...   \n",
       "3       202.0       340.0               64.0       235.0       428.0  ...   \n",
       "4       143.0       596.0              134.0       387.0       711.0  ...   \n",
       "\n",
       "   ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  ActionGeo_FeatureID  \\\n",
       "0               261.0        35.7131         47.2656                573.0   \n",
       "1               272.0        31.4167         34.3333                777.0   \n",
       "2               529.0        54.7680         45.8370                543.0   \n",
       "3               275.0        32.9000         35.3333                727.0   \n",
       "4               703.0        39.3498        -75.5148               1252.0   \n",
       "\n",
       "   NumArticles  year  month  day_of_year  day_of_week  is_weekend  \n",
       "0            2  2024     11          312            3           0  \n",
       "1            2  2024      9          266            6           1  \n",
       "2           10  2024     11          312            3           0  \n",
       "3           10  2024      9          266            6           1  \n",
       "4            1  2024      9          266            6           1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize an encoder for categorical data\n",
    "# encodes categorical data as integers (example \"USA\" may get 1 or whatever)\n",
    "# use -1 for unknown values to signal algorithm it's a new category it wasn't trained on\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# fit encoder on train set and transform it right away\n",
    "df_train[categorical_columns] = encoder.fit_transform(df_train[categorical_columns])\n",
    "\n",
    "# check the result\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32afb927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>...</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.055750</td>\n",
       "      <td>8.007875</td>\n",
       "      <td>5.766625</td>\n",
       "      <td>3.40725</td>\n",
       "      <td>-6.470750</td>\n",
       "      <td>257.344000</td>\n",
       "      <td>481.058125</td>\n",
       "      <td>104.49250</td>\n",
       "      <td>258.191125</td>\n",
       "      <td>485.000875</td>\n",
       "      <td>...</td>\n",
       "      <td>431.311625</td>\n",
       "      <td>62.349349</td>\n",
       "      <td>43.667745</td>\n",
       "      <td>878.161250</td>\n",
       "      <td>5.378125</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.145375</td>\n",
       "      <td>266.326125</td>\n",
       "      <td>4.617250</td>\n",
       "      <td>0.678625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.326515</td>\n",
       "      <td>3.020464</td>\n",
       "      <td>2.114999</td>\n",
       "      <td>1.183563</td>\n",
       "      <td>6.713044</td>\n",
       "      <td>130.284336</td>\n",
       "      <td>248.846530</td>\n",
       "      <td>38.32725</td>\n",
       "      <td>125.400933</td>\n",
       "      <td>226.239862</td>\n",
       "      <td>...</td>\n",
       "      <td>222.067189</td>\n",
       "      <td>165.684497</td>\n",
       "      <td>179.380515</td>\n",
       "      <td>430.636955</td>\n",
       "      <td>3.992667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272770</td>\n",
       "      <td>39.027979</td>\n",
       "      <td>2.171944</td>\n",
       "      <td>0.467034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>-172.178309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>31.416700</td>\n",
       "      <td>-3.916670</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>133.00000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>405.500000</td>\n",
       "      <td>33.871900</td>\n",
       "      <td>34.333300</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>46.463900</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1287.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>146.00000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1402.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "count  8000.000000    8000.000000    8000.000000     8000.0     8000.000000   \n",
       "mean     13.055750       8.007875       5.766625    3.40725       -6.470750   \n",
       "std       4.326515       3.020464       2.114999   1.183563        6.713044   \n",
       "min       0.000000       0.000000       0.000000        1.0      -10.000000   \n",
       "25%      11.000000       7.000000       6.000000        4.0      -10.000000   \n",
       "50%      16.000000      10.000000       7.000000        4.0      -10.000000   \n",
       "75%      16.000000      10.000000       7.000000        4.0       -9.000000   \n",
       "max      16.000000      10.000000       7.000000        4.0        8.500000   \n",
       "\n",
       "        Actor1Code   Actor1Name  Actor1CountryCode   Actor2Code   Actor2Name  \\\n",
       "count  8000.000000  8000.000000         8000.00000  8000.000000  8000.000000   \n",
       "mean    257.344000   481.058125          104.49250   258.191125   485.000875   \n",
       "std     130.284336   248.846530           38.32725   125.400933   226.239862   \n",
       "min       0.000000     0.000000            0.00000     0.000000     0.000000   \n",
       "25%     143.000000   299.000000           64.00000   163.000000   329.000000   \n",
       "50%     240.000000   455.000000          133.00000   290.000000   528.000000   \n",
       "75%     411.000000   756.000000          134.00000   387.000000   711.000000   \n",
       "max     477.000000   847.000000          146.00000   442.000000   750.000000   \n",
       "\n",
       "       ...  ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "count  ...         8000.000000    8000.000000     8000.000000   \n",
       "mean   ...          431.311625      62.349349       43.667745   \n",
       "std    ...          222.067189     165.684497      179.380515   \n",
       "min    ...            0.000000     -44.000000     -172.178309   \n",
       "25%    ...          271.000000      31.416700       -3.916670   \n",
       "50%    ...          405.500000      33.871900       34.333300   \n",
       "75%    ...          670.000000      46.463900       38.000000   \n",
       "max    ...          777.000000     999.000000      999.000000   \n",
       "\n",
       "       ActionGeo_FeatureID  NumArticles    year        month  day_of_year  \\\n",
       "count          8000.000000       8000.0  8000.0  8000.000000  8000.000000   \n",
       "mean            878.161250     5.378125  2024.0     9.145375   266.326125   \n",
       "std             430.636955     3.992667     0.0     1.272770    39.027979   \n",
       "min               0.000000          1.0  2024.0     1.000000    27.000000   \n",
       "25%             530.000000          2.0  2024.0     9.000000   266.000000   \n",
       "50%             837.000000          4.0  2024.0     9.000000   266.000000   \n",
       "75%            1287.000000         10.0  2024.0     9.000000   266.000000   \n",
       "max            1402.000000         60.0  2024.0    12.000000   350.000000   \n",
       "\n",
       "       day_of_week   is_weekend  \n",
       "count  8000.000000  8000.000000  \n",
       "mean      4.617250     0.678625  \n",
       "std       2.171944     0.467034  \n",
       "min       0.000000     0.000000  \n",
       "25%       3.000000     0.000000  \n",
       "50%       6.000000     1.000000  \n",
       "75%       6.000000     1.000000  \n",
       "max       6.000000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of these new values\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5042b",
   "metadata": {},
   "source": [
    "Very interesting to see: GoldsteinScale is very skewed.\n",
    "It represents intensity of interactions between actors.\n",
    "Negative values mean conflictual interactions.\n",
    "A -10 is actually an act of war.\n",
    "A positive value means a cooperative action.\n",
    "\n",
    "In this data, there's almost only bad events happening.\n",
    "I don't know if this is due to my hashing in SQL, just random or because most\n",
    "of the news happens to be about bad things.\n",
    "I mean from my own personal experience, it makes sense.\n",
    "A lot of news focuses on bad things.\n",
    "\n",
    "I don't want to go any deeper into interpreting this, but it's noteworthy in\n",
    "my opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5daef94",
   "metadata": {},
   "source": [
    "## No scaling or normalization is needed\n",
    "\n",
    "The range of the features differs a lot.\n",
    "Many algorithms would suffer from this.\n",
    "\n",
    "However, I already decided to use tree-based models only.\n",
    "This is actually for a personal reason.\n",
    "I will have to use these algorithms for a different project in the future, so I\n",
    "already want to gather some experience and get familiar with them.\n",
    "\n",
    "Tree-based models like XGBoost, CatBoost, and LightGBM do not require feature\n",
    "scaling or normalization for either categorical features (integer encoded) or\n",
    "numerical features.\n",
    "\n",
    "These algorithms split data based on feature values and thresholds, not on\n",
    "Euclidean distance, so scaling has no effect on their performance or accuracy.\n",
    "\n",
    "Label-encoded categorical variables are treated as distinct categories,\n",
    "regardless of their actual integer value range.\n",
    "\n",
    "The models can be trained directly with the current integer and numeric features.\n",
    "\n",
    "If I had used different algorithms, I would have to check if scaling or\n",
    "normalization is needed.\n",
    "Here, however, this is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03c60d",
   "metadata": {},
   "source": [
    "## Divide into features and target\n",
    "\n",
    "What's left now is to extract the features and the target.\n",
    "The target is the number of articles in the media `NumArticles`.\n",
    "The features are all the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1d3984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>...</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>35.7131</td>\n",
       "      <td>47.2656</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>31.4167</td>\n",
       "      <td>34.3333</td>\n",
       "      <td>777.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>54.7680</td>\n",
       "      <td>45.8370</td>\n",
       "      <td>543.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>32.9000</td>\n",
       "      <td>35.3333</td>\n",
       "      <td>727.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>39.3498</td>\n",
       "      <td>-75.5148</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0       11.0            7.0            6.0          4            -9.0   \n",
       "1       16.0           10.0            7.0          4           -10.0   \n",
       "2       11.0            7.0            6.0          4            -9.0   \n",
       "3       16.0           10.0            7.0          4           -10.0   \n",
       "4       16.0           10.0            7.0          4           -10.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  Actor2Code  Actor2Name  ...  \\\n",
       "0       187.0       330.0               61.0         0.0        14.0  ...   \n",
       "1       203.0       339.0               64.0       209.0       381.0  ...   \n",
       "2       416.0       792.0              133.0       328.0       584.0  ...   \n",
       "3       202.0       340.0               64.0       235.0       428.0  ...   \n",
       "4       143.0       596.0              134.0       387.0       711.0  ...   \n",
       "\n",
       "   ActionGeo_CountryCode  ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "0                   65.0               261.0        35.7131         47.2656   \n",
       "1                   66.0               272.0        31.4167         34.3333   \n",
       "2                  127.0               529.0        54.7680         45.8370   \n",
       "3                   66.0               275.0        32.9000         35.3333   \n",
       "4                  151.0               703.0        39.3498        -75.5148   \n",
       "\n",
       "   ActionGeo_FeatureID  year  month  day_of_year  day_of_week  is_weekend  \n",
       "0                573.0  2024     11          312            3           0  \n",
       "1                777.0  2024      9          266            6           1  \n",
       "2                543.0  2024     11          312            3           0  \n",
       "3                727.0  2024      9          266            6           1  \n",
       "4               1252.0  2024      9          266            6           1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features and check result\n",
    "X_train = df_train.drop(columns=[\"NumArticles\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d6583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     2\n",
       "2    10\n",
       "3    10\n",
       "4     1\n",
       "Name: NumArticles, dtype: Int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target and check resuls\n",
    "y_train = df_train[\"NumArticles\"]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378f060",
   "metadata": {},
   "source": [
    "Amazing! I'd say everything looks great.\n",
    "This should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b0f59",
   "metadata": {},
   "source": [
    "## Collect the steps and refactor them into a function\n",
    "\n",
    "This exact same logic must be applied to the df_test, too, so the model will be\n",
    "able to make meaningful predictions.\n",
    "\n",
    "I will collect the steps and refactor them into a function.\n",
    "This function can not only be used for the df_test, but it will also be useful\n",
    "for later when I export this notebook as a script.\n",
    "\n",
    "Make sure to use the df_train and then apply whatever it learned to the df_test.\n",
    "Never learn from the full dataset or from the df_test itself.\n",
    "An example for this is checking number of missing values to decide which columns\n",
    "to drop and scaling the data in case it is needed.\n",
    "\n",
    "Make sure to fit encoding (like category codes) on the training set, then apply\n",
    "to the test set to avoid data leakage.\n",
    "\n",
    "Make sure train and test columns are in the same order.\n",
    "\n",
    "Save the data to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446b02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for saving the labels\n",
    "def save_series_as_parquet(series, filepath):\n",
    "    \"\"\"Save a pandas Series as parquet file\"\"\"\n",
    "    # Convert Series to DataFrame with proper column name\n",
    "    df = series.to_frame(name=series.name if series.name else 'target')\n",
    "    df.to_parquet(filepath)\n",
    "\n",
    "# function for data preparation\n",
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    is_train: bool,\n",
    "    encoder: Optional[OrdinalEncoder] = None,\n",
    "    encoder_path: Optional[str] = None,\n",
    "    save_data: bool = False,\n",
    "    save_path_dir: Optional[str] = None,\n",
    "    path_repo: Optional[str] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare data for training or testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constants\n",
    "    \n",
    "    # target value or rather label\n",
    "    target_label = \"NumArticles\"\n",
    "    \n",
    "    # path to intermediate data\n",
    "    if save_data == True:\n",
    "        PATH_DATA = Path(path_repo) / \"data/intermediate\"\n",
    "\n",
    "    # Handle missing values\n",
    "\n",
    "    # check for missing values and extract columns with >= 50% missing\n",
    "    missing_rates = df.isnull().mean()\n",
    "    columns_high_missing = missing_rates[missing_rates >= 0.5].index.tolist()\n",
    "\n",
    "    # drop columns with 50% or more missing\n",
    "    df = df.drop(columns=columns_high_missing)\n",
    "\n",
    "    # automatically identify column types\n",
    "    numerical_columns = df.select_dtypes(\n",
    "        include=['int64', 'float64']\n",
    "    ).columns.tolist()\n",
    "    categorical_columns = df.select_dtypes(\n",
    "        include=['object', 'string']\n",
    "    ).columns.tolist()\n",
    "    \n",
    "    # create imputation strategy dynamically\n",
    "    # numerical values: use 999 (far outside normal range)\n",
    "    # categorical values: use \"UNKNOWN\"\n",
    "    imputation_strategy = {}\n",
    "\n",
    "    # add categorical imputation (UNKNOWN for all)\n",
    "    for col in categorical_columns:\n",
    "        imputation_strategy[col] = \"UNKNOWN\"\n",
    "\n",
    "    # add numerical imputation (999 for all)\n",
    "    for col in numerical_columns:\n",
    "        imputation_strategy[col] = 999\n",
    "\n",
    "    # fill missing values with strategy\n",
    "    df.fillna(imputation_strategy, inplace=True)\n",
    "\n",
    "    # Handle time and data columns\n",
    "    # convert column \"SQLDATE\" to more meaningful date and time info\n",
    "    # this will allos models to learn from it better\n",
    "\n",
    "    # convert to datetime first\n",
    "    df['date'] = pd.to_datetime(df['SQLDATE'], format='%Y%m%d')\n",
    "\n",
    "    # extract useful components\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear  # 1-365\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # drop the intermediate date column and the original date related columns\n",
    "    df = df.drop([\"date\", \"SQLDATE\", \"MonthYear\"], axis=1)\n",
    "\n",
    "\n",
    "    # Handle categorical data by numerical encoding\n",
    "    \n",
    "    # if train data is passed, fit_transform and save encoder\n",
    "    if is_train == True:\n",
    "        \n",
    "        # initialize an encoder for categorical data\n",
    "        # encodes categorical data as integers\n",
    "        # example \"USA\" may get 1 or whatever\n",
    "        # use -1 for unknown values\n",
    "        # this signals algorithm it's a new category it wasn't trained on\n",
    "        encoder = OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        )\n",
    "        \n",
    "        # fit encoder on train set and transform data it right away\n",
    "        df[categorical_columns] = encoder.fit_transform(df[categorical_columns])\n",
    "        \n",
    "        # if data is supposed to be saved, save encoder to file\n",
    "        if save_data == True:\n",
    "            encoder_path = 'ordinal_encoder_prototype.pkl' \n",
    "            joblib.dump(encoder, encoder_path)\n",
    "\n",
    "            # log as part of a custom model (for later use with ML model)\n",
    "            with mlflow.start_run():\n",
    "                # log just the encoder as artifact for now\n",
    "                mlflow.log_artifact(encoder_path, artifact_path='preprocessing')\n",
    "\n",
    "                # clean up local file after logging\n",
    "                # so it's in just one location: artifact store\n",
    "                os.remove(encoder_path)\n",
    "\n",
    "\n",
    "    # if test data is passed, load the encoder and transform test data\n",
    "    elif is_train == False:\n",
    "        \n",
    "        # we need the run_id to locate the encoder in the artifact store\n",
    "        if encoder is None and encoder_path is None:\n",
    "            raise ValueError(\"For test data, either 'encoder' object or 'encoder_path' (run_id) must be provided\")\n",
    "        \n",
    "        # if encoder object is passed directly, use it\n",
    "        if encoder is not None:\n",
    "            loaded_encoder = encoder\n",
    "        \n",
    "        # if encoder_path (run_id) is provided, load from artifact store\n",
    "        elif encoder_path is not None:\n",
    "            # download the encoder from MLflow artifact store\n",
    "            # encoder_path should be the run_id where the encoder was logged\n",
    "            artifact_path = mlflow.artifacts.download_artifacts(\n",
    "                f\"runs:/{encoder_path}/preprocessing/ordinal_encoder_prototype.pkl\"\n",
    "            )\n",
    "            # load the encoder from the downloaded file\n",
    "            loaded_encoder = joblib.load(artifact_path)\n",
    "            \n",
    "            # clean up: delete the temporary downloaded file\n",
    "            os.remove(artifact_path)\n",
    "        \n",
    "        # apply the loaded encoder to transform test data (only transform, no fitting)\n",
    "        df[categorical_columns] = loaded_encoder.transform(df[categorical_columns])\n",
    "\n",
    "\n",
    "    # Extract features and labels\n",
    "    # get features\n",
    "    X = df.drop(columns=[target_label])\n",
    "\n",
    "    # get target\n",
    "    y = df[target_label]\n",
    "    \n",
    "    \n",
    "    # Save data to parquet files if desired\n",
    "    if save_data == True:\n",
    "        \n",
    "        # ensure the intermediate data directory exists\n",
    "        PATH_DATA.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # if path to directory to save data to was passed, use it\n",
    "        if save_path_dir is not None:\n",
    "            save_name = PATH_DATA / save_path_dir\n",
    "        # if not passed, use a default path\n",
    "        else:\n",
    "            # count number of directories in intermediate data dir\n",
    "            num_dirs = sum(1 for p in PATH_DATA.iterdir() if p.is_dir())\n",
    "            save_name = PATH_DATA / f\"gdelt_events_2024_subset_version_{num_dirs}\"\n",
    "            \n",
    "        # ensure the save directory exists\n",
    "        save_name.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # switch between train and test features and labels\n",
    "        if is_train == True:\n",
    "            X_name = \"X_train\"\n",
    "            y_name = \"y_train\"\n",
    "        else:\n",
    "            X_name = \"X_test\"\n",
    "            y_name = \"y_test\"\n",
    "            \n",
    "        # save data to parquet files\n",
    "        X.to_parquet(save_name / f\"{X_name}.parquet\")\n",
    "        save_series_as_parquet(y, save_name / f\"{y_name}.parquet\")\n",
    "\n",
    "    # always return features and labels\n",
    "    # return encoder if train was used\n",
    "    if is_train == True:\n",
    "        return X, y, encoder\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "425c8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of previously processed train data to compare if output is same\n",
    "df_train_backup = df_train.copy()\n",
    "X_train_backup = X_train.copy()\n",
    "y_train_backup = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4833d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# briefly check if backup worked\n",
    "print(df_train_backup.equals(df_train))\n",
    "print(X_train_backup.equals(X_train))\n",
    "print(y_train_backup.equals(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa803da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data again fresh from file, because it was already processed\n",
    "df_train = pd.read_parquet(PATH_DATA / \"gdelt_events_2024_subset_10k_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1558459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = df_train,\n",
    "    is_train = True,\n",
    "    save_data = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d502b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names comparison:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "Value comparison:\n",
      "X values equal: True\n",
      "y values equal: True\n",
      "\n",
      "Index comparison:\n",
      "[ True  True  True ...  True  True  True]\n",
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# compare column names\n",
    "print(\"Column names comparison:\")\n",
    "print(X_train_backup.columns == X_train_new.columns)\n",
    "\n",
    "\n",
    "# compare values element by element (ignoring index/column names)\n",
    "print(\"\\nValue comparison:\")\n",
    "print(f\"X values equal: {X_train_new.values.shape == X_train_backup.values.shape and (X_train_new.values == X_train_backup.values).all()}\")\n",
    "print(f\"y values equal: {y_train_new.values.shape == y_train_backup.values.shape and (y_train_new.values == y_train_backup.values).all()}\")\n",
    "\n",
    "# compare index now\n",
    "print(\"\\nIndex comparison:\")\n",
    "print(X_train_new.index == X_train_backup.index)\n",
    "print(y_train_new.index == y_train_backup.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fae3d8",
   "metadata": {},
   "source": [
    "Great! The data in there is the same.\n",
    "All column names match and the values are the same, too for both features (X)\n",
    "and the labels (y).\n",
    "Even the index is the same. I actually didn't expect that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea2d46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for test data\n",
    "# pass the new encoder here\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = df_test,\n",
    "    is_train = False,\n",
    "    save_data = False,\n",
    "    encoder = encoder_new\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2784b",
   "metadata": {},
   "source": [
    "I'll now also check this function for the test data.\n",
    "It's bad to look at test data, but I guess verifying the code works by\n",
    "comparing columns and printing the head is acceptable.\n",
    "Without it, I wouldn't even know if my function works.\n",
    "\n",
    "In theory, I could also just run it in `is_train = False` mode for the train\n",
    "data, but I want to be completely sure.\n",
    "\n",
    "Honestly, this cannot be seen as data leakage, because I will obtain like zero\n",
    "information from looking at these numbers.\n",
    "To make this even more clear, I'll just print the first row.\n",
    "This is just enough for me to see the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4d9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing columns:\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>...</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0        6.0            3.0            2.0          1             8.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  Actor2Code  Actor2Name  ...  \\\n",
       "0       422.0       802.0              134.0        86.0       710.0  ...   \n",
       "\n",
       "   ActionGeo_CountryCode  ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "0                   -1.0                -1.0           34.0             9.0   \n",
       "\n",
       "   ActionGeo_FeatureID  year  month  day_of_year  day_of_week  is_weekend  \n",
       "0                 -1.0  2024      7          190            0           0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare columns to backup -> columns must match\n",
    "print(\"Comparing columns:\")\n",
    "print(X_test_new.columns == X_train_backup.columns)\n",
    "\n",
    "# print only first row to get some feedback if function works\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9954d94",
   "metadata": {},
   "source": [
    "Amazing! This can be used!\n",
    "\n",
    "But I need to test the writing function.\n",
    "This will also log to MLFLow, so there are many more break points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d96c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run welcoming-wasp-672 at: http://127.0.0.1:5001/#/experiments/1/runs/f55cb43906854b59b8485232f2667bb8\n",
      "🧪 View experiment at: http://127.0.0.1:5001/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# test the function for train data\n",
    "X_train_new, y_train_new, encoder_new = prepare_data(\n",
    "    df = df_train,\n",
    "    is_train = True,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b684d",
   "metadata": {},
   "source": [
    "Great! This works!\n",
    "The data is saved and the encoder is logged to MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c3cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function for test data\n",
    "# pass run ID as encoder path\n",
    "X_test_new, y_test_new = prepare_data(\n",
    "    df = df_test,\n",
    "    is_train = False,\n",
    "    save_data = True,\n",
    "    save_path_dir = \"notebook_prototyping\",\n",
    "    path_repo = PATH_REPO,\n",
    "    encoder_path = \"27d90f27450249d987677a5b7fa18167\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c8ea504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventCode</th>\n",
       "      <th>EventBaseCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>QuadClass</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>Actor1Code</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2Code</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>...</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>ActionGeo_Lat</th>\n",
       "      <th>ActionGeo_Long</th>\n",
       "      <th>ActionGeo_FeatureID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventCode  EventBaseCode  EventRootCode  QuadClass  GoldsteinScale  \\\n",
       "0        6.0            3.0            2.0          1             8.0   \n",
       "\n",
       "   Actor1Code  Actor1Name  Actor1CountryCode  Actor2Code  Actor2Name  ...  \\\n",
       "0       422.0       802.0              134.0        86.0       710.0  ...   \n",
       "\n",
       "   ActionGeo_CountryCode  ActionGeo_ADM1Code  ActionGeo_Lat  ActionGeo_Long  \\\n",
       "0                   -1.0                -1.0           34.0             9.0   \n",
       "\n",
       "   ActionGeo_FeatureID  year  month  day_of_year  day_of_week  is_weekend  \n",
       "0                 -1.0  2024      7          190            0           0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to first row of previous run\n",
    "X_test_new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771bf2e",
   "metadata": {},
   "source": [
    "Amazing! This works, too! So, this is my data prep and I can go on I think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499f1bd",
   "metadata": {},
   "source": [
    "I leave some code here for later reference.\n",
    "\n",
    "I haven't verified this works yet, but this is how I can likely do it:\n",
    "\n",
    "```python\n",
    "# bundle a model witht the encoder\n",
    "mlflow.pyfunc.log_model(\"model_with_preprocessing\",\n",
    "                        python_model=YourModelWrapper(),\n",
    "                        artifacts={'encoder': encoder_path})\n",
    "\n",
    "# load the encoder in future scripts/notebooks\n",
    "# if this is actually needed, because I have the function\n",
    "run_id = \"<your_run_id>\"\n",
    "encoder_path = mlflow.artifacts.download_artifacts(f\"runs/{run_id}/preprocessing/ordinal_encoder.pkl\")\n",
    "loaded_encoder = joblib.load(encoder_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c68ee",
   "metadata": {},
   "source": [
    "## Get a 1000 Samples Subset from Processed Train Data\n",
    "\n",
    "10k rows is already not that much data for ML, but it can still run for some\n",
    "time.\n",
    "For rapid prototyping in interactive Jupyter notebooks, I will get an even\n",
    "smaller subset of just 1k rows.\n",
    "\n",
    "I will draw it directly from the processed train data, and use it when I\n",
    "develop in interactive mode.\n",
    "I can then run a script using the full data in background later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "192aad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 25)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 1000 random samples\n",
    "df_train_subset1k = df_train.sample(n=1000, random_state=42)\n",
    "\n",
    "# check it out\n",
    "df_train_subset1k.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc54cd",
   "metadata": {},
   "source": [
    "I won't save this subset right here, because I will extract the logic to a\n",
    "script now anyway and do it there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
